{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPyeZwVfvtuP0JC7zqesbLl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bdi2357/CoverLetter/blob/main/CoverLetrrer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U google-generativeai"
      ],
      "metadata": {
        "id": "hTAXNfaoRqDr"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/bdi2357/CoverLetter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0bLtjxrR_Ya",
        "outputId": "d07ea14f-ba0c-4a0e-b677-cfbc8644747d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CoverLetter'...\n",
            "remote: Enumerating objects: 30, done.\u001b[K\n",
            "remote: Counting objects: 100% (30/30), done.\u001b[K\n",
            "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "remote: Total 30 (delta 13), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (30/30), 93.34 KiB | 4.67 MiB/s, done.\n",
            "Resolving deltas: 100% (13/13), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import textwrap\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ],
      "metadata": {
        "id": "At05GNhPPQ-s"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q PyPDF2"
      ],
      "metadata": {
        "id": "4qshbooyX7EJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd61b4e8-d664-4078-9fd0-75f92ba5dd7f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m225.3/232.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install docx\n",
        "!pip install fpdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLepXwZwYBfz",
        "outputId": "a2d5b43f-e19d-45d6-8813-7bab7b26a2e7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting docx\n",
            "  Downloading docx-0.2.4.tar.gz (54 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/54.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from docx) (4.9.4)\n",
            "Requirement already satisfied: Pillow>=2.0 in /usr/local/lib/python3.10/dist-packages (from docx) (9.4.0)\n",
            "Building wheels for collected packages: docx\n",
            "  Building wheel for docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx: filename=docx-0.2.4-py3-none-any.whl size=53892 sha256=ba192702cded5fcbc15a2b10288a0c3e31e4bcff9ae5c6d3bdfb5bcb34d62e8d\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/f5/1d/e09ba2c1907a43a4146d1189ae4733ca1a3bfe27ee39507767\n",
            "Successfully built docx\n",
            "Installing collected packages: docx\n",
            "Successfully installed docx-0.2.4\n",
            "Collecting fpdf\n",
            "  Downloading fpdf-1.7.2.tar.gz (39 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: fpdf\n",
            "  Building wheel for fpdf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fpdf: filename=fpdf-1.7.2-py2.py3-none-any.whl size=40704 sha256=040dcd9cfcddf4303a15b1d18b0867d8fe4ef1880c64359a63af139f337217d8\n",
            "  Stored in directory: /root/.cache/pip/wheels/f9/95/ba/f418094659025eb9611f17cbcaf2334236bf39a0c3453ea455\n",
            "Successfully built fpdf\n",
            "Installing collected packages: fpdf\n",
            "Successfully installed fpdf-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-docx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIHuTeqilm84",
        "outputId": "d3e88193-e0e0-40ea-c602-ee683d22fc1f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.4)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.12.2)\n",
            "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/244.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m235.5/244.3 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-docx\n",
            "Successfully installed python-docx-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from genai import GenerativeModel\n",
        "from docx import Document\n",
        "from docx.shared import Pt\n",
        "import re\n",
        "import time"
      ],
      "metadata": {
        "id": "a1sqyTAmRfRw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Used to securely store your API key\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "eB61SnIWVKVm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import textwrap\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ],
      "metadata": {
        "id": "-hpD7lN6K1O2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "eyq9gB2IV8E7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel('gemini-1.5-flash')"
      ],
      "metadata": {
        "id": "OdyzB6kgYN9b"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PyPDF2 import PdfReader\n",
        "\n",
        "def load_and_extract_text(file_path):\n",
        "    with open(file_path, 'rb') as file:\n",
        "        pdf_reader = PdfReader(file)\n",
        "        text = \"\"\n",
        "        for page in pdf_reader.pages:\n",
        "            text += page.extract_text()\n",
        "        return text"
      ],
      "metadata": {
        "id": "scs-j7SadNPa"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "yrZFX_ZGCAKu"
      },
      "outputs": [],
      "source": [
        "def generate_cover_letter(model,cv_text, job_description_text):\n",
        "\n",
        "    prompt = f\"\"\"Based on the provided job description and CV, write a concise, compelling and personalized cover letter that highlights relevant skills and experiences.\n",
        "\n",
        "    Job Description:\\n{job_description_text}\\n\\nCV:\\n{cv_text}\\n\\n\n",
        "\n",
        "    Tailor the letter to the specific job requirements and showcase the candidate's match for the position. Be sure to mention specific accomplishments and quantify results whenever possible. Keep the tone professional and precise based on the cv.\n",
        "    As concise as possible no more than 4 sentences. Avoid using adjectives unless neccessary , as less as possible , do not use emotive adjectives in any case, use only factual information based on the cv_text , finalize with best regards, Name where the name of the applicant is taken from the CV\"\"\"\n",
        "    print(\"HERE generate_cover_letter\")\n",
        "    response = model.generate_content(prompt)  # Remove the 'context' argument\n",
        "    print(\"after generate_cover_letter\")\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "job_description = \"\"\" We're seeking an AI Developer to join our team. In this role, you'll leverage artificial intelligence and machine learning techniques to improve the invoice reconciliation process and create a unified data format across various financial systems.\n",
        "\n",
        "Responsibilities:\n",
        "- Develop and implement AI and machine learning models to automate invoice reconciliation\n",
        "- Create intelligent systems to unify diverse invoice data into a standardized format\n",
        "- Design and build natural language processing (NLP) solutions to extract key information from unstructured invoice data\n",
        "- Implement machine learning algorithms to identify patterns, anomalies, and potential errors in financial data\n",
        "- Collaborate with finance and accounting teams to understand business requirements and integrate AI solutions into existing workflows\n",
        "- Continuously improve and optimize AI models based on new data and changing business needs\n",
        "\n",
        "Requirements:\n",
        "- Masters or PhD in Computer Science, Artificial Intelligence, or related field\n",
        "- 3+ years of experience developing AI and machine learning solutions, preferably in finance or accounting domains\n",
        "- Strong programming skills in Python and experience with ML frameworks (e.g., TensorFlow, PyTorch, scikit-learn)\n",
        "- Experience with NLP techniques and text analysis\n",
        "- Familiarity with financial systems, ERP software, and accounting principles\n",
        "- Knowledge of data privacy and security best practices\n",
        "- Excellent problem-solving skills and ability to translate complex business requirements into technical solutions\n",
        "\n",
        "No agencies please.\n",
        "This individual must be available for 30h/week and during UK working hours.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "fh4UxsGzyvCh"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_text = load_and_extract_text(\"CoverLetter/Data/CV_GPT_rev.pdf\")"
      ],
      "metadata": {
        "id": "w9qtW_RXdDwD"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "dedzxL_GqtL8",
        "outputId": "c0efe572-8e7f-4992-9feb-862c3d8771f6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Itay\\nBen-Dan\\nHaarava\\n20,\\nHerzliya\\nP.\\nO.\\nBox\\n5990,\\nHerzliya,\\nIsrael\\n46100\\nCellular:\\n+972544539284\\nEmail:\\nitaybd@gmail.com\\nProfessional\\nSummary\\nFull\\nStack\\nMachine\\nLearning\\nEngineer\\nwith\\nextensive\\nexperience\\nin\\ndata\\nengineering,\\nmodel\\ndevelopment,\\ndeployment,\\nand\\nmaintenance.\\nExpertise\\nin\\nsports,\\nfinance,\\nand\\nrobotics,\\nwith\\na\\nfocus\\non\\nadvanced\\ndata\\nanalytics\\nand\\nmachine\\nlearning,\\nincluding\\nLLMs\\nand\\nmulti-agent\\nsystems.\\nWork\\nExperience\\n2017-Present:\\nMachine\\nLearning\\nand\\nData\\nScience\\nConsultant\\n●\\nDeveloped\\npredictive\\nmodels\\nfrom\\nscratch,\\nincluding\\ndeployment.\\n●\\nConducted\\nexploratory\\ndata\\nanalysis\\nand\\nadvanced\\nfeature\\ngeneration.\\n●\\nIntegrated\\ndata\\nfrom\\nvarious\\nsources\\ninto\\nunified\\nformats.\\n●\\nDeveloped\\npolicy\\ngenerative\\nmodels\\nusing\\nreinforcement\\nlearning.\\n2017-Present:\\nFounder\\nand\\nHead\\nof\\nResearch,\\nFinzor\\nLtd.\\n●\\nDeveloped\\nportfolio\\nmanagement\\nand\\ninvestment\\nanalysis\\ntools.\\n●\\nLed\\na\\nteam\\nto\\ndeliver\\nsoftware\\nproducts\\nfrom\\ndesign\\nto\\nproduction.\\n2016-2017:\\nPrincipal\\nMachine\\nLearning,\\nPalo\\nAlto\\nNetworks\\n●\\nApplied\\nmachine\\nlearning\\nto\\nreverse\\nengineering\\nand\\nmalware\\nanalysis.\\n●\\nCreated\\nadaptive\\nmodels\\nfor\\nupdating\\nanti-malware\\nfilters\\nand\\nclassifiers.\\n2015-2016:\\nSenior\\nData\\nScientist,\\nSparkBeyond\\n●\\nWorked\\non\\nbig\\ndata\\npredictive\\nanalytics\\nand\\nmachine\\nlearning.\\n●\\nApplied\\nautomatic\\nfeature\\ngeneration\\nmethods\\nto\\ntime\\nseries\\nanalysis\\nand\\nreinforcement\\nlearning.\\n2011-2015:\\nSenior\\nQuantitative\\nResearcher,\\nWorldQuant●\\nDeveloped\\nautomated\\ncomputational\\nmethods\\nfor\\nquant-driven\\nstrategies.\\n●\\nApplied\\npredictive\\nanalytics\\nand\\nstatistical\\nmethods\\nacross\\nvarious\\nassets.\\n2010-2011:\\nSenior\\nSoftware\\nEngineer,\\nBroadcom\\n●\\nDesigned\\nnetwork\\nand\\npacket\\nprocessing\\nmethodologies.\\n●\\nImplemented\\nadvanced\\nautomated\\ntesting\\nmethods.\\n2008-2009:\\nFounder,\\nGenous\\nVision\\n●\\nDeveloped\\nalgorithms\\nfor\\nrecognizing\\nanatomies\\nin\\nultrasound\\nimages.\\nEducation\\n2009:\\nPh.D.\\nin\\nMathematics,\\nTechnion,\\nHaifa\\n●\\nTopic:\\nDiscrete\\nGeometry\\n●\\nSupervisor:\\nDr.\\nRom\\nPinchasi\\n2004:\\nM.Sc.\\nin\\nMathematics,\\nTechnion,\\nHaifa\\n●\\nTopic:\\nGame\\nTheory\\n●\\nThesis:\\nTime\\nSharing\\nunder\\nDichotomous\\nPreferences\\n●\\nGrade:\\n95\\n●\\nSupervisor:\\nProf.\\nRon\\nHolzman\\n2002:\\nB.Sc.\\nin\\nMathematics\\nand\\nComputer\\nScience,\\nTechnion,\\nHaifa\\n●\\nCum\\nLaude\\nSkills\\n●\\nProgramming\\nLanguages:\\nPython,\\nR,\\nC++,\\nJava\\n●\\nMachine\\nLearning\\nFrameworks:\\nTensorFlow,\\nPyTorch,\\nScikit-learn\\n●\\nData\\nAnalysis\\nTools:\\nPandas,\\nNumPy,\\nSQL\\n●\\nOther\\nTechnologies:\\nDocker,\\nKubernetes,\\nAWS,\\nGit,\\nLinux\\nProjects\\nTreeModelVis●\\nVisualization\\ntool\\nfor\\ntree-based\\nmodels,\\naiding\\nin\\nunderstanding\\ndecision\\npaths\\nand\\nfeature\\nimportance.\\n●\\nTechnologies\\nUsed:\\nPython,\\nD3.js\\n●\\nGitHub\\nRepository\\nPublications\\n●\\nPoints\\nwith\\nLarge\\nQuadrant\\nDepth.\\nJoCG\\n2(1):\\n128-143\\n(2011)\\n●\\nPoints\\nwith\\nlarge\\nquadrant\\ndepth.\\nSymposium\\non\\nComputational\\nGeometry\\n2010:\\n358-364\\n●\\nOn\\na\\nproblem\\nabout\\nquadrant\\ndepth.\\nComput.\\nGeom.\\n43(6-7):\\n587-592\\n(2010)\\n●\\nPoints\\nwith\\nlarge\\nalphadepth.\\nJ.\\nComb.\\nTheory,\\nSer.\\nA\\n116(3):\\n747-755\\n(2009)\\nContact\\nInformation\\n●\\nEmail:\\nitaybd@gmail.com\\n●\\nLinkedIn:\\nItay\\nBen-Dan\\nLinkedIn\\nProfile\\nThis\\nCV\\nis\\nconcise\\nand\\ntailored,\\nhighlighting\\nkey\\nskills\\nand\\nexperience\\nin\\na\\nclean,\\norganized\\nformat.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_cover_letter(model,cv_text, job_description).text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "xO8AqhoydojT",
        "outputId": "b826070e-6e94-43fa-926f-76d4b673e3c7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HERE generate_cover_letter\n",
            "after generate_cover_letter\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Dear Hiring Manager,\\n\\nI am writing to express my interest in the AI Developer position at your company. My experience in developing and deploying AI solutions, particularly in finance and data engineering, aligns well with your requirements. I have a strong foundation in Python, machine learning frameworks (TensorFlow, PyTorch, scikit-learn), and NLP techniques, as demonstrated in my work at Finzor Ltd. and Palo Alto Networks. I am confident in my ability to contribute to your team's success in automating invoice reconciliation and data unification.\\n\\nBest regards, \\n\\nItay Ben-Dan \\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_key_phrases(model, cover_letter_text, job_description_text, num_phrases=4):\n",
        "    \"\"\"\n",
        "    Extracts key phrases from a cover letter based on their relevance to a job description using Gemini.\n",
        "\n",
        "    Args:\n",
        "        model: The Gemini language model instance.\n",
        "        cover_letter_text: The text of the cover letter.\n",
        "        job_description_text: The text of the job description.\n",
        "        num_phrases: The number of phrases to extract (default is 4).\n",
        "\n",
        "    Returns:\n",
        "        A list of the most important phrases.\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = f\"\"\"Given the following cover letter and job description, identify the {num_phrases} most important words or two-word expressions in the cover letter that are most relevant to the job description.\n",
        "    These words or Two words expression should show professional skills of the candidate they should reflecy the candidate as a doer, if it is an action like developing/programming it should be accompanied with the subject of the action. such as :\n",
        "    developing AI models.\n",
        "\n",
        "    Cover Letter:\n",
        "    {cover_letter_text}\n",
        "\n",
        "    Job Description:\n",
        "    {job_description_text}\n",
        "    \"\"\"\n",
        "    print(\"HERE key phrases\")\n",
        "    response = model.generate_content(prompt)\n",
        "\n",
        "    # Extract key phrases from response\n",
        "    important_phrases = response.text.split('\\n')  # Assuming each phrase is on a new line\n",
        "    print(len(important_phrases))\n",
        "    return important_phrases"
      ],
      "metadata": {
        "id": "hCqxY9clh-rH"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time.sleep(3)\n",
        "job_description = job_description #load_and_extract_text(\"job_description.pdf\")\n",
        "cv_text = load_and_extract_text(\"CoverLetter/Data/CV_GPT_rev.pdf\")\n",
        "cover_letter_text = generate_cover_letter(model,cv_text, job_description).text\n",
        "for k in cover_letter_text.split(\".\"):\n",
        "  print(k)\n",
        "time.sleep(3)\n",
        "key_phrases = extract_key_phrases(model, cover_letter_text, job_description, num_phrases=3)\n",
        "for k in key_phrases:\n",
        "  print(\"#\"*30)\n",
        "  print(k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "CC26_KnJNl7k",
        "outputId": "7f770b93-ff91-4608-dd4a-260ba0571abd"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HERE generate_cover_letter\n",
            "after generate_cover_letter\n",
            "Dear Hiring Manager,\n",
            "\n",
            "I am writing to express my strong interest in the AI Developer position at your company\n",
            " My extensive experience in machine learning, including model development, deployment, and maintenance in financial domains, aligns well with the requirements of this role\n",
            " I have a proven track record of developing predictive models from scratch, integrating data from various sources, and implementing NLP solutions for data extraction\n",
            " I am confident in my ability to leverage my skills to automate invoice reconciliation and create a unified data format across your financial systems\n",
            "\n",
            "\n",
            "Best regards,\n",
            "\n",
            "Itay Ben-Dan \n",
            "\n",
            "HERE key phrases\n",
            "6\n",
            "##############################\n",
            "Here are the 3 most important words/phrases from the cover letter, aligned with the job description, and highlighting the candidate's skills:\n",
            "##############################\n",
            "\n",
            "##############################\n",
            "1. **Developing predictive models:** This directly matches the job description's focus on developing AI models for invoice reconciliation and data unification. It showcases the candidate's experience in building AI solutions from scratch.\n",
            "##############################\n",
            "2. **Implementing NLP solutions:**  This aligns with the job's requirement for NLP skills to extract information from unstructured data. The cover letter highlights the candidate's practical experience in this area.\n",
            "##############################\n",
            "3. **Automating invoice reconciliation:** This directly addresses a key responsibility outlined in the job description. The cover letter emphasizes the candidate's confidence in applying their skills to solve this specific business challenge. \n",
            "##############################\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_strings(key_phrases):\n",
        "  R= []\n",
        "  for k in key_phrases:\n",
        "    A = (re.findall('\\*\\*.*?\\*\\*',k))\n",
        "    if len(A)>0:\n",
        "      R += re.findall('[A-Za-z\\ 0-9]+',A[0])\n",
        "  return R"
      ],
      "metadata": {
        "id": "ZPDpn1jp0eS1"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extract_strings(extract_key_phrases(model, cover_letter_text, job_description, num_phrases=3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "5IeUwuSB4tJx",
        "outputId": "94ec26a2-0898-48b2-fd65-d95e8826b901"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HERE key phrases\n",
            "6\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Developing predictive models',\n",
              " 'Implementing NLP solutions',\n",
              " 'Automating invoice reconciliation']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from docx import Document\n",
        "from docx.shared import Pt\n",
        "from docx.oxml.ns import qn\n",
        "from docx.oxml import OxmlElement\n",
        "\n",
        "def bold_strings_in_text(text, bold_strings, output_doc):\n",
        "    # Create a new Document\n",
        "    doc = Document()\n",
        "\n",
        "    # Add the text to the document, with specified strings in bold\n",
        "    para = doc.add_paragraph()\n",
        "    parts = split_text(text, bold_strings)\n",
        "\n",
        "    for part in parts:\n",
        "        if part.lower() in [s.lower() for s in bold_strings]:\n",
        "            run = para.add_run(part)\n",
        "            run.bold = True\n",
        "        else:\n",
        "            para.add_run(part)\n",
        "\n",
        "    # Save the document\n",
        "    doc.save(output_doc)\n",
        "\n",
        "def split_text(text, bold_strings):\n",
        "    import re\n",
        "    pattern = '|'.join(re.escape(s) for s in bold_strings)\n",
        "    parts = re.split(f'({pattern})', text)\n",
        "    print(parts)\n",
        "    return parts\n",
        "\n",
        "# Example usage\n",
        "text = \"This is a sample text. We want some words like sample and words to be bold.\"\n",
        "bold_strings = [\"sample\", \"words\"]\n",
        "bold_strings_in_text(text, bold_strings,\"output.docx\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpV3EAEf5AQG",
        "outputId": "33eed34c-f359-4b7b-dd9a-54ee76398a93"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['This is a ', 'sample', ' text. We want some ', 'words', ' like ', 'sample', ' and ', 'words', ' to be bold.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cl_text = generate_cover_letter(model,cv_text, job_description).text\n",
        "strings = extract_strings(extract_key_phrases(model, cl_text, job_description, num_phrases=3))\n",
        "bold_strings_in_text(cl_text, strings, \"test2.docx\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "Tqeq5Cgn5otS",
        "outputId": "a873e1f4-26db-46c1-d51f-795b6fb23589"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HERE generate_cover_letter\n",
            "after generate_cover_letter\n",
            "HERE key phrases\n",
            "6\n",
            "['Dear Hiring Manager,\\n\\nI am writing to express my strong interest in the AI Developer position at your company. My experience in developing and deploying AI solutions in finance, including portfolio management and investment analysis, aligns well with your requirements. I have a proven track record of success in building predictive models, integrating diverse data sources, and applying ', 'NLP techniques', ' for information extraction. I am confident in my ability to leverage my skills to enhance your invoice reconciliation process and create a unified data format across your financial systems.\\n\\nBest regards,\\nItay Ben-Dan \\n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(strings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCzpElqwdp_n",
        "outputId": "4bbc1d8f-be17-4bcd-f742-8bf5f6afc9bc"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Developing AI solutions', 'Predictive models', 'NLP techniques']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cl_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "37GpRjmhHvFW",
        "outputId": "e1c7aa55-e5c8-44b8-ece1-b59e7305b072"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Dear Hiring Manager,\\n\\nI am writing to express my strong interest in the AI Developer position at your company. My experience in developing and deploying AI solutions in finance, including portfolio management and investment analysis, aligns well with your requirements. I have a proven track record of success in building predictive models, integrating diverse data sources, and applying NLP techniques for information extraction. I am confident in my ability to leverage my skills to enhance your invoice reconciliation process and create a unified data format across your financial systems.\\n\\nBest regards,\\nItay Ben-Dan \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxWAcOH0dcDX",
        "outputId": "f1f28299-8459-4b1d-af31-24b8fba4df77"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CoverLetter  output.docx  sample_data  test2.docx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-docx reportlab pypandoc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfIQHI25AyE2",
        "outputId": "6878faea-a865-442b-dc5b-e5a31ccde871"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.10/dist-packages (1.1.2)\n",
            "Collecting reportlab\n",
            "  Downloading reportlab-4.2.2-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting pypandoc\n",
            "  Downloading pypandoc-1.13-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.4)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.12.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from reportlab) (9.4.0)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from reportlab) (5.2.0)\n",
            "Downloading reportlab-4.2.2-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypandoc-1.13-py3-none-any.whl (21 kB)\n",
            "Installing collected packages: reportlab, pypandoc\n",
            "Successfully installed pypandoc-1.13 reportlab-4.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from docx import Document\n",
        "import re\n",
        "import pypandoc\n",
        "from reportlab.lib.pagesizes import letter\n",
        "from reportlab.pdfgen import canvas"
      ],
      "metadata": {
        "id": "asVLIGH_CVwd"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install docx2pdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCfE-HPko4M3",
        "outputId": "b1e4d271-c6e6-4ad8-b11c-fa41e0596da5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting docx2pdf\n",
            "  Downloading docx2pdf-0.1.8-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from docx2pdf) (4.66.5)\n",
            "Downloading docx2pdf-0.1.8-py3-none-any.whl (6.7 kB)\n",
            "Installing collected packages: docx2pdf\n",
            "Successfully installed docx2pdf-0.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from docx import Document\n",
        "import re\n",
        "from reportlab.lib.pagesizes import letter\n",
        "from reportlab.pdfgen import canvas\n",
        "from io import BytesIO\n"
      ],
      "metadata": {
        "id": "5WKdksutokW3"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_docx_to_pdf(input_docx, output_pdf, title, name):\n",
        "    # Convert docx to PDF using BytesIO to avoid creating temporary files\n",
        "    pdf_buffer = BytesIO()\n",
        "    pdf = canvas.Canvas(pdf_buffer, pagesize=letter)\n",
        "    width, height = letter\n",
        "\n",
        "    # Add title and name\n",
        "    pdf.setFont(\"Helvetica-Bold\", 16)\n",
        "    pdf.drawString(72, height - 72, title)\n",
        "    pdf.setFont(\"Helvetica\", 12)\n",
        "    pdf.drawString(72, height - 92, name)\n",
        "\n",
        "    # Read the docx file and add content to the PDF\n",
        "    doc = Document(input_docx)\n",
        "    text_object = pdf.beginText(72, height - 112)\n",
        "    text_object.setFont(\"Helvetica\", 10)\n",
        "\n",
        "    for para in doc.paragraphs:\n",
        "        for run in para.runs:\n",
        "            if run.bold:\n",
        "                text_object.setFont(\"Helvetica-Bold\", 10)\n",
        "            else:\n",
        "                text_object.setFont(\"Helvetica\", 10)\n",
        "            text_object.textLine(run.text)\n",
        "\n",
        "    pdf.drawText(text_object)\n",
        "    pdf.save()"
      ],
      "metadata": {
        "id": "rQjyQehNCYX3"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name = \"Itay Ben-Dan\"\n",
        "title = \"AI Developer Application\"\n",
        "cl_pdf_name = \"output.docx\"\n",
        "output_doc_name = \"cl_output.pdf\"\n",
        "convert_docx_to_pdf(cl_pdf_name, output_doc_name, title, name)"
      ],
      "metadata": {
        "id": "k1bGwb0pCpsM"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from reportlab.lib.pagesizes import letter\n",
        "from reportlab.pdfgen import canvas\n",
        "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
        "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n",
        "from reportlab.lib.units import inch\n",
        "import re\n",
        "\n",
        "def create_pdf_with_bold_strings(output_pdf, title, name, text, bold_strings):\n",
        "    # Create the PDF document\n",
        "    pdf = SimpleDocTemplate(output_pdf, pagesize=letter)\n",
        "    styles = getSampleStyleSheet()\n",
        "    story = []\n",
        "\n",
        "    # Define custom styles for title and body text\n",
        "    title_style = ParagraphStyle(name='Title', fontSize=16, leading=20, spaceAfter=20, alignment=1)\n",
        "    name_style = ParagraphStyle(name='Name', fontSize=12, leading=14, spaceAfter=14, alignment=1)\n",
        "    body_style = styles['BodyText']\n",
        "    bold_style = ParagraphStyle(name='Bold', parent=styles['BodyText'], fontName='Helvetica-Bold')\n",
        "\n",
        "    # Add title\n",
        "    story.append(Paragraph(title, title_style))\n",
        "\n",
        "    # Add name\n",
        "    story.append(Paragraph(name, name_style))\n",
        "    story.append(Spacer(1, 12))\n",
        "\n",
        "    # Process and add the main text with bold strings\n",
        "    parts = split_text(text, bold_strings)\n",
        "    for part in parts:\n",
        "        if any(re.fullmatch(re.escape(b), part, re.IGNORECASE) for b in bold_strings):\n",
        "            story.append(Paragraph(part, bold_style))\n",
        "        else:\n",
        "            story.append(Paragraph(part, body_style))\n",
        "\n",
        "    # Build the PDF\n",
        "    pdf.build(story)\n",
        "\n",
        "def split_text(text, bold_strings):\n",
        "    pattern = '|'.join(re.escape(s) for s in bold_strings)\n",
        "    parts = re.split(f'({pattern})', text, flags=re.IGNORECASE)\n",
        "    return parts\n",
        "\n",
        "# Example usage\n",
        "cv_text = \"John Doe\"\n",
        "text = \"\"\"Dear Hiring Manager,\n",
        "\n",
        "I am writing to express my strong interest in the AI Developer position at your company. My extensive experience in developing and deploying AI solutions, particularly in finance and data analytics, aligns well with your requirements. My accomplishments include building predictive models from scratch, integrating data from diverse sources into unified formats, and creating adaptive models for updating anti-malware filters. I am confident that my skills and experience would be a valuable asset to your team.\n",
        "\"\"\"\n",
        "bold_strings = [\"developing and deploying AI solutions\", \"integrating data from diverse sources\", \"creating adaptive models\"]\n",
        "output_pdf = \"output_professional.pdf\"\n",
        "title = \"AI Developer Application\"\n",
        "\n",
        "create_pdf_with_bold_strings(output_pdf, title, cv_text, text, bold_strings)\n"
      ],
      "metadata": {
        "id": "V5Nww8qVsII_"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "!git clone https://github.com/openai/openai-quickstart-node.git\n",
        "!pip install openai\n",
        "!pip install tiktoken\n",
        "!pip install python-dotenv\n",
        "import os\n",
        "os.chdir(\"openai-quickstart-node\")\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "J7_M39b1Nhmh",
        "outputId": "8fcc3f90-bb3c-4151-8fee-70f952c564eb"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n!git clone https://github.com/openai/openai-quickstart-node.git\\n!pip install openai\\n!pip install tiktoken\\n!pip install python-dotenv\\nimport os\\nos.chdir(\"openai-quickstart-node\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUboZeAQMVUc",
        "outputId": "1601f720-d1fa-4944-923b-8774cb0ac021"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.5)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.10.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.7.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import sys\n",
        "from google.colab import userdata\n",
        "\n",
        "OPENAI_API_KEY=userdata.get('OPENAI_API_KEY2')\n",
        "\n",
        "openai.api_key  = OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "rFaLFWH-5a4y"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from reportlab.lib.pagesizes import letter\n",
        "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n",
        "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
        "from docx import Document\n",
        "import re\n",
        "\n",
        "# Set your OpenAI API key\n",
        "\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "\n",
        "# Function to generate improved text using OpenAI API\n",
        "def generate_improved_text(prompt):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    return response['choices'][0]['message']['content'].strip()\n",
        "\n",
        "# Function to improve the cover letter\n",
        "def improve_cover_letter(cover_letter, critique):\n",
        "    prompt = f\"Given the following cover letter and critique, generate an improved version of the cover letter:\\n\\nCover Letter:\\n{cover_letter}\\n\\nCritique:\\n{critique}\\n\\nImproved Cover Letter:\"\n",
        "    return generate_improved_text(prompt)\n",
        "\n",
        "# Function to improve the CV\n",
        "def improve_cv(cv_text, critique):\n",
        "    prompt = f\"Given the following CV and critique, generate an improved version of the CV:\\n\\nCV:\\n{cv_text}\\n\\nCritique:\\n{critique}\\n\\nImproved CV:\"\n",
        "    return generate_improved_text(prompt)\n",
        "\n",
        "# Function to create a PDF from text\n",
        "def create_pdf(output_pdf, title, name, text):\n",
        "    pdf = SimpleDocTemplate(output_pdf, pagesize=letter)\n",
        "    styles = getSampleStyleSheet()\n",
        "    story = []\n",
        "\n",
        "    # Define custom styles for title and body text\n",
        "    title_style = ParagraphStyle(name='Title', fontSize=16, leading=20, spaceAfter=20, alignment=1)\n",
        "    name_style = ParagraphStyle(name='Name', fontSize=12, leading=14, spaceAfter=14, alignment=1)\n",
        "    body_style = styles['BodyText']\n",
        "    bold_style = ParagraphStyle(name='Bold', parent=styles['BodyText'], fontName='Helvetica-Bold')\n",
        "\n",
        "    # Add title\n",
        "    story.append(Paragraph(title, title_style))\n",
        "\n",
        "    # Add name\n",
        "    story.append(Paragraph(name, name_style))\n",
        "    story.append(Spacer(1, 12))\n",
        "\n",
        "    # Process and add the main text with bold strings\n",
        "    parts = split_text(text, [])\n",
        "    for part in parts:\n",
        "        if any(re.fullmatch(re.escape(b), part, re.IGNORECASE) for b in []):\n",
        "            story.append(Paragraph(part, bold_style))\n",
        "        else:\n",
        "            story.append(Paragraph(part, body_style))\n",
        "\n",
        "    # Build the PDF\n",
        "    pdf.build(story)\n",
        "\n",
        "# Function to split text\n",
        "def split_text(text, bold_strings):\n",
        "    pattern = '|'.join(re.escape(s) for s in bold_strings)\n",
        "    parts = re.split(f'({pattern})', text, flags=re.IGNORECASE)\n",
        "    return parts\n",
        "\n",
        "# Example usage\n",
        "original_cover_letter = \"\"\"Dear Hiring Manager,\n",
        "\n",
        "I am writing to express my strong interest in the AI Developer position at your company. My extensive experience in developing and deploying AI solutions, particularly in finance and data analytics, aligns well with your requirements. My accomplishments include building predictive models from scratch, integrating data from diverse sources into unified formats, and creating adaptive models for updating anti-malware filters. I am confident that my skills and experience would be a valuable asset to your team.\n",
        "\"\"\"\n",
        "cover_letter_critique = \"\"\"Strong Points: Relevance, Specific Accomplishments, Professional Tone.\n",
        "Weak Points: Lack of Specifics, Formatting, Connection to Job Description.\n",
        "Suggested Improvements: Include Specific Technologies, Better Formatting, Tailor to Job Description.\n",
        "Rating: 6/10\n",
        "Probability of Follow-Up Contact: 0.4 (40%)\n",
        "\"\"\"\n",
        "\n",
        "original_cv = \"\"\"Itay Ben-Dan\n",
        "Haarava 20, Herzliya\n",
        "P. O. Box 5990, Herzliya, Israel 46100\n",
        "Cellular: +972544539284\n",
        "Email: itaybd@gmail.com\n",
        "\n",
        "Professional Summary\n",
        "Full Stack Machine Learning Engineer with extensive experience in data engineering, model development, deployment, and maintenance. Expertise in sports, finance, and robotics, with a focus on advanced data analytics and machine learning, including LLMs and multi-agent systems.\n",
        "\n",
        "Work Experience\n",
        "2017-Present: Machine Learning and Data Science Consultant\n",
        "• Developed predictive models from scratch, including deployment.\n",
        "• Conducted exploratory data analysis and advanced feature generation.\n",
        "• Integrated data from various sources into unified formats.\n",
        "• Developed policy generative models using reinforcement learning.\n",
        "\n",
        "2017-2020: Founder and Head of Research, Finzor Ltd.\n",
        "• Developed portfolio management and investment analysis tools.\n",
        "• Led a team to deliver software products from design to production.\n",
        "\n",
        "2016-2017: Principal Machine Learning, Palo Alto Networks\n",
        "• Applied machine learning to reverse engineering and malware analysis.\n",
        "• Created adaptive models for updating anti-malware filters and classifiers.\n",
        "\n",
        "2015-2016: Senior Data Scientist, SparkBeyond\n",
        "• Worked on big data predictive analytics and machine learning.\n",
        "• Applied automatic feature generation methods to time series analysis and reinforcement learning.\n",
        "\n",
        "2011-2015: Senior Quantitative Researcher, WorldQuant\n",
        "• Developed automated computational methods for quant-driven strategies.\n",
        "• Applied predictive analytics and statistical methods across various assets.\n",
        "\n",
        "2010-2011: Senior Software Engineer, Broadcom\n",
        "• Designed network and packet processing methodologies.\n",
        "• Implemented advanced automated testing methods.\n",
        "\n",
        "2008-2009: Founder, Genous Vision\n",
        "• Developed algorithms for recognizing anatomies in ultrasound images.\n",
        "\n",
        "Education\n",
        "2009: Ph.D. in Mathematics, Technion, Haifa\n",
        "• Topic: Discrete Geometry\n",
        "• Supervisor: Dr. Rom Pinchasi\n",
        "\n",
        "2004: M.Sc. in Mathematics, Technion, Haifa\n",
        "• Topic: Game Theory\n",
        "• Thesis: Time Sharing under Dichotomous Preferences\n",
        "• Grade: 95\n",
        "• Supervisor: Prof. Ron Holzman\n",
        "\n",
        "2002: B.Sc. in Mathematics and Computer Science, Technion, Haifa\n",
        "• Cum Laude\n",
        "\n",
        "Skills\n",
        "• Programming Languages: Python, R, C++, Java\n",
        "• Machine Learning Frameworks: TensorFlow, PyTorch, Scikit-learn\n",
        "• Data Analysis Tools: Pandas, NumPy, SQL\n",
        "• Other Technologies: Docker, Kubernetes, AWS, Git, Linux\n",
        "\n",
        "Projects\n",
        "TreeModelVis\n",
        "• Visualization tool for tree-based models, aiding in understanding decision paths and feature importance.\n",
        "• Technologies Used: Python, D3.js\n",
        "• GitHub Repository\n",
        "\n",
        "Publications\n",
        "• Points with Large Quadrant Depth. JoCG 2(1): 128-143 (2011)\n",
        "• Points with large quadrant depth. Symposium on Computational Geometry 2010: 358-364\n",
        "• On a problem about quadrant depth. Comput. Geom. 43(6-7): 587-592 (2010)\n",
        "• Points with large alphadepth. J. Comb. Theory, Ser. A 116(3): 747-755 (2009)\n",
        "\n",
        "Contact Information\n",
        "• Email: itaybd@gmail.com\n",
        "• LinkedIn: Itay Ben-Dan LinkedIn Profile\n",
        "\"\"\"\n",
        "\n",
        "cv_critique = \"\"\"Strong Points: Comprehensive Experience, Relevant Roles, Educational Background.\n",
        "Weak Points: Length and Density, Lack of Specific Results, Skills Section.\n",
        "Suggested Improvements: Highlight Key Accomplishments, Focus on Relevance, Skills Section.\n",
        "Rating: 7/10\n",
        "Probability of Follow-Up Contact: 0.5 (50%)\n",
        "\"\"\"\n",
        "\n",
        "improved_cover_letter = improve_cover_letter(original_cover_letter, cover_letter_critique)\n",
        "improved_cv = improve_cv(original_cv, cv_critique)\n",
        "\n",
        "# Save improved cover letter as PDF\n",
        "create_pdf(\"improved_cover_letter.pdf\", \"AI Developer Application\", \"John Doe\", improved_cover_letter)\n",
        "\n",
        "# Save improved CV as PDF\n",
        "create_pdf(\"improved_cv.pdf\", \"Curriculum Vitae\", \"Itay Ben-Dan\", improved_cv)\n"
      ],
      "metadata": {
        "id": "K4Ksn0DwPbhW"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#prompt = f\"\"\"Based on the provided job description and CV, write a concise, compelling and personalized cover letter that highlights relevant skills and experiences.\n",
        "\n",
        "#    Job Description:\\n{job_description_text}\\n\\nCV:\\n{cv_text}\\n\\n\n",
        "\n",
        "#    Tailor the letter to the specific job requirements and showcase the candidate's match for the position. Be sure to mention specific accomplishments and quantify results whenever possible. Keep the tone professional and precise based on the cv.\n",
        "#    As concise as possible no more than 4 sentences. Avoid using adjectives unless neccessary , as less as possible , do not use emotive adjectives in any case, use only factual information based on the cv_text , finalize with best regards, Name where the name of the applicant is taken from the CV\"\"\"\n"
      ],
      "metadata": {
        "id": "siwXieTaJhUf"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "def generate_improved_text(prompt):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a highly experienced career coach and recruiter. Your job is to critically evaluate cover letters based on job descriptions, resumes (CVs), and the expected professional standards for the role. You provide detailed feedback on various aspects of the cover letter.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    return response['choices'][0]['message']['content'].strip()\n",
        "\n",
        "# Function to create the prompt\n",
        "def create_critique_prompt(cover_letter_pdf, cv_text, job_description):\n",
        "    prompt = f\"\"\"\n",
        "    I need you to critique a cover letter that was submitted for an AI Developer role. The cover letter is provided as a PDF file, and I'll summarize its content below. The candidate's resume (CV) and the job description are also provided. Please evaluate the cover letter based on the following criteria:\n",
        "\n",
        "    1. **Relevance to the Job**: Does the cover letter effectively address the specific responsibilities and requirements of the job as described in the job description?\n",
        "    2. **Form and Structure**: Is the cover letter well-organized and professionally formatted? Does it follow standard cover letter conventions?\n",
        "    3. **Reliability**: Does the cover letter convey a sense of reliability and trustworthiness? Is it free from errors and inconsistencies?\n",
        "    4. **Professional Matching**: Does the cover letter demonstrate that the candidate's skills, experience, and background match the job's requirements?\n",
        "    5. **Overall Impression**: How compelling is the cover letter in making the case that the candidate is a strong fit for the role?\n",
        "\n",
        "    After critiquing the cover letter on these criteria, please provide an overall grade on a scale of 1-10, where 10 is the best.\n",
        "\n",
        "    Here are the details:\n",
        "\n",
        "    **Cover Letter Summary**:\n",
        "    (Provide a summary of the content of the cover letter extracted from the PDF.)\n",
        "\n",
        "    **Resume (CV) Text**:\n",
        "    {cv_text}\n",
        "\n",
        "    **Job Description**:\n",
        "    {job_description}\n",
        "\n",
        "    Please provide a detailed critique with specific points for improvement and an overall grade.\n",
        "    \"\"\"\n",
        "    return prompt"
      ],
      "metadata": {
        "id": "ehj8i6iXlwPx"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from reportlab.lib.pagesizes import letter\n",
        "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n",
        "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
        "\n",
        "# Set your OpenAI API key\n",
        "\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "\n",
        "# Function to generate improved text using OpenAI API\n",
        "def generate_improved_text(prompt):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    return response['choices'][0]['message']['content'].strip()\n",
        "\n",
        "# Function to improve the cover letter\n",
        "def improve_cover_letter(CV_text, cover_letter,job_description_text):\n",
        "    critique = create_critique_prompt(cover_letter, cv_text, job_description_text)\n",
        "    #prompt = f\"Given the following cover letter and critique, generate an improved version of the cover letter:\\n\\nCover Letter:\\n{cover_letter}\\n\\nCritique:\\n{critique}\\n\\nImproved Cover Letter:\"\n",
        "    prompt = f\"\"\"Based on the provided job description, original cover letter (the one that the critique refers to), and CV, write a concise, exact, factual and personalized cover letter that highlights relevant skills and experiences. the resulting letter should take into account the critique and improve accordingly\n",
        "\n",
        "\n",
        "   Job Description:\\n{job_description_text}\\n\\nCV:\\n{CV_text}\\n\\nCritique:\\n\\ncover_letter:\\n{cover_letter}\\n\\nCritique:\\n{critique}\\n\\n\n",
        "\n",
        "    Tailor the letter to the specific job requirements and showcase the candidate's match for the position. Be sure to mention specific accomplishments and quantify results whenever possible. Keep the tone professional and precise based on the cv.\n",
        "   As concise as possible no more than 4 sentences. Avoid using adjectives unless neccessary , as less as possible , do not use emotive adjectives in any case, use only factual information based on the cv_text , finalize with best regards, Name where the name of the applicant is taken from the CV\"\"\"\n",
        "\n",
        "    return generate_improved_text(prompt)\n",
        "\n",
        "# Function to improve the CV\n",
        "def improve_cv(cv_text, critique):\n",
        "    prompt = f\"Given the following CV and critique, generate an improved version of the CV:\\n\\nCV:\\n{cv_text}\\n\\nCritique:\\n{critique}\\n\\nImproved CV:\"\n",
        "    return generate_improved_text(prompt)\n",
        "\n",
        "# Function to create a PDF from text\n",
        "def create_pdf(output_pdf, title, name, text):\n",
        "    print(output_pdf)\n",
        "    pdf = SimpleDocTemplate(output_pdf, pagesize=letter)\n",
        "    styles = getSampleStyleSheet()\n",
        "    story = []\n",
        "\n",
        "    # Define custom styles for title and body text\n",
        "    title_style = ParagraphStyle(name='Title', fontSize=16, leading=20, spaceAfter=20, alignment=1)\n",
        "    name_style = ParagraphStyle(name='Name', fontSize=12, leading=14, spaceAfter=14, alignment=1)\n",
        "    body_style = styles['BodyText']\n",
        "    bold_style = ParagraphStyle(name='Bold', parent=styles['BodyText'], fontName='Helvetica-Bold')\n",
        "\n",
        "    # Add title\n",
        "    story.append(Paragraph(title, title_style))\n",
        "\n",
        "    # Add name\n",
        "    story.append(Paragraph(name, name_style))\n",
        "    story.append(Spacer(1, 12))\n",
        "\n",
        "    # Process and add the main text\n",
        "    paragraphs = text.split(\"\\n\\n\")\n",
        "    for para in paragraphs:\n",
        "        story.append(Paragraph(para.replace('\\n', '<br/>'), body_style))\n",
        "        story.append(Spacer(1, 12))\n",
        "\n",
        "    # Build the PDF\n",
        "    pdf.build(story)\n",
        "\n"
      ],
      "metadata": {
        "id": "fJTJ--QxtJRz"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "original_cover_letter = \"\"\"Dear Hiring Manager,\n",
        "\n",
        "I am writing to express my strong interest in the AI Developer position at your company. My extensive experience in developing and deploying AI solutions, particularly in finance and data analytics, aligns well with your requirements. My accomplishments include building predictive models from scratch, integrating data from diverse sources into unified formats, and creating adaptive models for updating anti-malware filters. I am confident that my skills and experience would be a valuable asset to your team.\n",
        "\"\"\"\n",
        "cover_letter_critique = \"\"\"Strong Points: Relevance, Specific Accomplishments, Professional Tone.\n",
        "Weak Points: Lack of Specifics, Formatting, Connection to Job Description.\n",
        "Suggested Improvements: Include Specific Technologies, Better Formatting, Tailor to Job Description.\n",
        "Rating: 6/10\n",
        "Probability of Follow-Up Contact: 0.4 (40%)\n",
        "\"\"\"\n",
        "\n",
        "original_cv = \"\"\"Itay Ben-Dan\n",
        "Haarava 20, Herzliya\n",
        "P. O. Box 5990, Herzliya, Israel 46100\n",
        "Cellular: +972544539284\n",
        "Email: itaybd@gmail.com\n",
        "\n",
        "Professional Summary\n",
        "Full Stack Machine Learning Engineer with extensive experience in data engineering, model development, deployment, and maintenance. Expertise in sports, finance, and robotics, with a focus on advanced data analytics and machine learning, including LLMs and multi-agent systems.\n",
        "\n",
        "Work Experience\n",
        "2017-Present: Machine Learning and Data Science Consultant\n",
        "• Developed predictive models from scratch, including deployment.\n",
        "• Conducted exploratory data analysis and advanced feature generation.\n",
        "• Integrated data from various sources into unified formats.\n",
        "• Developed policy generative models using reinforcement learning.\n",
        "\n",
        "2017-2020: Founder and Head of Research, Finzor Ltd.\n",
        "• Developed portfolio management and investment analysis tools.\n",
        "• Led a team to deliver software products from design to production.\n",
        "\n",
        "2016-2017: Principal Machine Learning, Palo Alto Networks\n",
        "• Applied machine learning to reverse engineering and malware analysis.\n",
        "• Created adaptive models for updating anti-malware filters and classifiers.\n",
        "\n",
        "2015-2016: Senior Data Scientist, SparkBeyond\n",
        "• Worked on big data predictive analytics and machine learning.\n",
        "• Applied automatic feature generation methods to time series analysis and reinforcement learning.\n",
        "\n",
        "2011-2015: Senior Quantitative Researcher, WorldQuant\n",
        "• Developed automated computational methods for quant-driven strategies.\n",
        "• Applied predictive analytics and statistical methods across various assets.\n",
        "\n",
        "2010-2011: Senior Software Engineer, Broadcom\n",
        "• Designed network and packet processing methodologies.\n",
        "• Implemented advanced automated testing methods.\n",
        "\n",
        "2008-2009: Founder, Genous Vision\n",
        "• Developed algorithms for recognizing anatomies in ultrasound images.\n",
        "\n",
        "Education\n",
        "2009: Ph.D. in Mathematics, Technion, Haifa\n",
        "• Topic: Discrete Geometry\n",
        "• Supervisor: Dr. Rom Pinchasi\n",
        "\n",
        "2004: M.Sc. in Mathematics, Technion, Haifa\n",
        "• Topic: Game Theory\n",
        "• Thesis: Time Sharing under Dichotomous Preferences\n",
        "• Grade: 95\n",
        "• Supervisor: Prof. Ron Holzman\n",
        "\n",
        "2002: B.Sc. in Mathematics and Computer Science, Technion, Haifa\n",
        "• Cum Laude\n",
        "\n",
        "Skills\n",
        "• Programming Languages: Python, R, C++, Java\n",
        "• Machine Learning Frameworks: TensorFlow, PyTorch, Scikit-learn\n",
        "• Data Analysis Tools: Pandas, NumPy, SQL\n",
        "• Other Technologies: Docker, Kubernetes, AWS, Git, Linux\n",
        "\n",
        "Projects\n",
        "TreeModelVis\n",
        "• Visualization tool for tree-based models, aiding in understanding decision paths and feature importance.\n",
        "• Technologies Used: Python, D3.js\n",
        "• GitHub Repository\n",
        "\n",
        "Publications\n",
        "• Points with Large Quadrant Depth. JoCG 2(1): 128-143 (2011)\n",
        "• Points with large quadrant depth. Symposium on Computational Geometry 2010: 358-364\n",
        "• On a problem about quadrant depth. Comput. Geom. 43(6-7): 587-592 (2010)\n",
        "• Points with large alphadepth. J. Comb. Theory, Ser. A 116(3): 747-755 (2009)\n",
        "\n",
        "Contact Information\n",
        "• Email: itaybd@gmail.com\n",
        "• LinkedIn: Itay Ben-Dan LinkedIn Profile\n",
        "\"\"\"\n",
        "\n",
        "cv_critique = \"\"\"Strong Points: Comprehensive Experience, Relevant Roles, Educational Background.\n",
        "Weak Points: Length and Density, Lack of Specific Results, Skills Section.\n",
        "Suggested Improvements: Highlight Key Accomplishments, Focus on Relevance, Skills Section.\n",
        "Rating: 7/10\n",
        "Probability of Follow-Up Contact: 0.5 (50%)\n",
        "\"\"\"\n",
        "\n",
        "improved_cover_letter = improve_cover_letter(original_cover_letter, cover_letter_critique)\n",
        "improved_cv = improve_cv(original_cv, cv_critique)\n",
        "\n",
        "# Save improved cover letter as PDF\n",
        "create_pdf(\"improved_cover_letter.pdf\", \"AI Developer Application\", \"John Doe\", improved_cover_letter)\n",
        "\n",
        "# Save improved CV as PDF\n",
        "create_pdf(\"improved_cv.pdf\", \"Curriculum Vitae\", \"Itay Ben-Dan\", improved_cv)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "01VweaAlKFlF",
        "outputId": "1ca8ac04-6535-4497-a2bc-94b08dd6c4df"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "improve_cover_letter() missing 2 required positional arguments: 'job_description_text' and 'critique'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-0f39bb6eaa75>\u001b[0m in \u001b[0;36m<cell line: 96>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m \"\"\"\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m \u001b[0mimproved_cover_letter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimprove_cover_letter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_cover_letter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcover_letter_critique\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0mimproved_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimprove_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_cv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv_critique\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: improve_cover_letter() missing 2 required positional arguments: 'job_description_text' and 'critique'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "#generate_cover_letter\n",
        "#extract_key_phrases\n",
        "#create_pdf_with_bold_strings(output_pdf, title, cv_text, text, bold_strings)\n",
        "#improve_cover_letter\n",
        "#improved_cover_letter\n",
        "#extract_key_phrases(model, cover_letter_text, job_description, num_phrases=3)\n",
        "\n",
        "cv_text = load_and_extract_text(\"CoverLetter/Data/CV_GPT_rev.pdf\")\n",
        "cover_letter_text = generate_cover_letter(model,cv_text, job_description).text\n",
        "bold_strings = extract_strings(extract_key_phrases(model, cover_letter_text, job_description, num_phrases=3))\n",
        "create_pdf_with_bold_strings(output_pdf, title, cv_text, text, bold_strings)\n",
        "improved_cover_letter = improve_cover_letter(cv_text,cover_letter_text,job_description)\n",
        "improved_cv = improve_cv(original_cv, cv_critique)\n",
        "\n",
        "#job_description"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "Z5Gq7NGyUIUd",
        "outputId": "7b05cc5e-2250-4fcc-f1b2-16ca0410802b"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HERE generate_cover_letter\n",
            "after generate_cover_letter\n",
            "HERE key phrases\n",
            "6\n",
            "CPU times: user 464 ms, sys: 32.7 ms, total: 497 ms\n",
            "Wall time: 40.9 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cover_letter_critique"
      ],
      "metadata": {
        "id": "ja6LUZQSmf6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_cv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "l7w3XuGTeY9h",
        "outputId": "1915178a-3454-4091-a424-b38efa322901"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Itay Ben-Dan\\nHaarava 20, Herzliya\\nP. O. Box 5990, Herzliya, Israel 46100\\nCellular: +972544539284\\nEmail: itaybd@gmail.com\\n\\nProfessional Summary\\nFull Stack Machine Learning Engineer with extensive experience in data engineering, model development, deployment, and maintenance. Expertise in sports, finance, and robotics, with a focus on advanced data analytics and machine learning, including LLMs and multi-agent systems.\\n\\nWork Experience\\n2017-Present: Machine Learning and Data Science Consultant\\n• Developed predictive models from scratch, including deployment.\\n• Conducted exploratory data analysis and advanced feature generation.\\n• Integrated data from various sources into unified formats.\\n• Developed policy generative models using reinforcement learning.\\n\\n2017-2020: Founder and Head of Research, Finzor Ltd.\\n• Developed portfolio management and investment analysis tools.\\n• Led a team to deliver software products from design to production.\\n\\n2016-2017: Principal Machine Learning, Palo Alto Networks\\n• Applied machine learning to reverse engineering and malware analysis.\\n• Created adaptive models for updating anti-malware filters and classifiers.\\n\\n2015-2016: Senior Data Scientist, SparkBeyond\\n• Worked on big data predictive analytics and machine learning.\\n• Applied automatic feature generation methods to time series analysis and reinforcement learning.\\n\\n2011-2015: Senior Quantitative Researcher, WorldQuant\\n• Developed automated computational methods for quant-driven strategies.\\n• Applied predictive analytics and statistical methods across various assets.\\n\\n2010-2011: Senior Software Engineer, Broadcom\\n• Designed network and packet processing methodologies.\\n• Implemented advanced automated testing methods.\\n\\n2008-2009: Founder, Genous Vision\\n• Developed algorithms for recognizing anatomies in ultrasound images.\\n\\nEducation\\n2009: Ph.D. in Mathematics, Technion, Haifa\\n• Topic: Discrete Geometry\\n• Supervisor: Dr. Rom Pinchasi\\n\\n2004: M.Sc. in Mathematics, Technion, Haifa\\n• Topic: Game Theory\\n• Thesis: Time Sharing under Dichotomous Preferences\\n• Grade: 95\\n• Supervisor: Prof. Ron Holzman\\n\\n2002: B.Sc. in Mathematics and Computer Science, Technion, Haifa\\n• Cum Laude\\n\\nSkills\\n• Programming Languages: Python, R, C++, Java\\n• Machine Learning Frameworks: TensorFlow, PyTorch, Scikit-learn\\n• Data Analysis Tools: Pandas, NumPy, SQL\\n• Other Technologies: Docker, Kubernetes, AWS, Git, Linux\\n\\nProjects\\nTreeModelVis\\n• Visualization tool for tree-based models, aiding in understanding decision paths and feature importance.\\n• Technologies Used: Python, D3.js\\n• GitHub Repository\\n\\nPublications\\n• Points with Large Quadrant Depth. JoCG 2(1): 128-143 (2011)\\n• Points with large quadrant depth. Symposium on Computational Geometry 2010: 358-364\\n• On a problem about quadrant depth. Comput. Geom. 43(6-7): 587-592 (2010)\\n• Points with large alphadepth. J. Comb. Theory, Ser. A 116(3): 747-755 (2009)\\n\\nContact Information\\n• Email: itaybd@gmail.com\\n• LinkedIn: Itay Ben-Dan LinkedIn Profile\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cover_letter_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "jn-QVW6JGmBz",
        "outputId": "095170aa-f008-4ac0-dcf5-ff514c0a4612"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Dear Hiring Manager,\\n\\nI am writing to express my strong interest in the AI Developer position at your company.  My extensive experience in developing and deploying machine learning models, particularly in the finance and accounting domains, aligns perfectly with the requirements of this role. I have successfully implemented AI solutions for tasks such as invoice reconciliation, data unification, and financial anomaly detection, demonstrating my ability to translate complex business needs into technical solutions.  I am confident that I can make a significant contribution to your team. \\n\\nBest regards,\\n\\nItay Ben-Dan \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "improved_cover_letter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "C2ICt3nc7zs7",
        "outputId": "68248399-d871-4799-b6c3-69e2676bb256"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Dear Hiring Team,\\n\\nI apply my PhD in Mathematics, Python expertise, and TensorFlow, PyTorch, Scikit-learn proficiency to drive improvements as an AI Developer. My background in unifying data into standardized formats (Machine Learning and Data Science Consultant, 2017-Present), automating invoice reconciliation via AI (Principal Machine Learning, Palo Alto Networks, 2016-2017), and deploying natural language processing solutions (Senior Data Scientist, SparkBeyond, 2015-2016), corresponds directly with your needs. \\n\\nBest regards,\\nItay Ben-Dan'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "job_description"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "nM6SwAu_cR_D",
        "outputId": "16f49a65-e690-4389-eb0e-d84eeb37cd92"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" We're seeking an AI Developer to join our team. In this role, you'll leverage artificial intelligence and machine learning techniques to improve the invoice reconciliation process and create a unified data format across various financial systems.\\n\\nResponsibilities:\\n- Develop and implement AI and machine learning models to automate invoice reconciliation\\n- Create intelligent systems to unify diverse invoice data into a standardized format\\n- Design and build natural language processing (NLP) solutions to extract key information from unstructured invoice data\\n- Implement machine learning algorithms to identify patterns, anomalies, and potential errors in financial data\\n- Collaborate with finance and accounting teams to understand business requirements and integrate AI solutions into existing workflows\\n- Continuously improve and optimize AI models based on new data and changing business needs\\n\\nRequirements:\\n- Masters or PhD in Computer Science, Artificial Intelligence, or related field\\n- 3+ years of experience developing AI and machine learning solutions, preferably in finance or accounting domains\\n- Strong programming skills in Python and experience with ML frameworks (e.g., TensorFlow, PyTorch, scikit-learn)\\n- Experience with NLP techniques and text analysis\\n- Familiarity with financial systems, ERP software, and accounting principles\\n- Knowledge of data privacy and security best practices\\n- Excellent problem-solving skills and ability to translate complex business requirements into technical solutions\\n\\nNo agencies please.\\nThis individual must be available for 30h/week and during UK working hours.\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "name = improved_cover_letter.split(\"\\n\")[-1]\n",
        "target_pdf_file = \"cover_letter_improved2.pdf\"\n",
        "title = (\"Cover Letter\")\n",
        "create_pdf(target_pdf_file, title, name,improved_cover_letter )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ww8IsHlNWRuZ",
        "outputId": "b5170b6a-c79f-443f-d208-f6ca4bfc678c"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cover_letter_improved2.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Example usage\n",
        "\n",
        "critique_prompt = create_critique_prompt(cover_letter_text, original_cv, job_description)\n",
        "response = generate_improved_text(critique_prompt)\n",
        "\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edrKUA7V_-Nu",
        "outputId": "729b92a8-aafb-4abc-9cc7-c166db06c8a3"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**1. Relevance to the Job**: The cover letter seems to lack direct references to the specific responsibilities and requirements of the AI Developer role that's described in the job description. While the candidate's cover letter talks about their experience in machine learning in general, it doesn't mention any specific work on artificial intelligence particularly aimed towards the financial or invoice reconciliation. Experience with natural language processing (NLP) for extracting key information from unstructured data is also not clear from the cover letter. The cover letter would have been stronger if the candidate directly discussed how his experience aligns with the job requirements (automating invoice reconciliation, NLP, working with financial data etc.).\n",
            "\n",
            "**2. Form and Structure**: Without seeing the actual cover letter, it's hard to comment accurately on its form and structure. However, based on the summary provided, the candidate has created a structure that outlines their experience and achievements chronologically. It would be beneficial to also see an explicit introductory section, where the candidate states what role they're applying for and why. A conclusion wrapping up their argument why they are the best fit for the role would also be beneficial. \n",
            "\n",
            "**3. Reliability**: Based on the resume provided, the candidate seems reliable and has exhibited commitment to his roles. The lack of explicit dates in some positions (in the cover letter summary) can pose a question about the duration of commitment to certain roles, so would be helpful to include.\n",
            "\n",
            "**4. Professional Matching**: The candidate has a strong background in machine learning, however, the job description specifies a requirement for experience in the finance or accounting domains. The cover letter summary does not highlight any relevant skills or experience in these areas. In addition, there's no mention of specific experience with NLP techniques, which is a requirement for the role.\n",
            "\n",
            "**5. Overall Impression**: While the candidate seems to possess a strong technical background in machine learning and data analysis, the cover letter does not do a good job in directly tying this experience to the specific needs of the role. A strong cover letter should act as a bridge between the resume and job description, explaining specifically and clearly how the candidate's background makes them suitable for the role.\n",
            "\n",
            "**Overall Grade**: 6 out of 10. The candidate has given substantial details about their professional experience, however, they have not directly connected this experience with the specific requirements of the job role. The cover letter could significantly benefit from a direct explanation of how their previous role experiences, skills, and achievements make them suitable for the role they're applying for.\n",
            "\n",
            "**Improvement Suggestions**: \n",
            "\n",
            "1. Highlight any experience they might have had with financial systems or invoice reconciliation.\n",
            "2. Specify their experience with NLP techniques.\n",
            "3. Begin the letter stating the role they're applying for and summarize why they're suitable for it.\n",
            "4. End with a strong conclusion pulling together their argument.\n",
            "5. Add Bible references to the job description and show a clear alignment between the job requirements and their skills/experience.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "doFW0YfLfMyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jBi2ecMMWVHG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}