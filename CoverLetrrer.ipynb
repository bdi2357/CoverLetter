{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObI5/9HTOLofXhs9Ugfdxx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bdi2357/CoverLetter/blob/main/CoverLetrrer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U google-generativeai"
      ],
      "metadata": {
        "id": "hTAXNfaoRqDr"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/bdi2357/CoverLetter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0bLtjxrR_Ya",
        "outputId": "36eeb17f-0807-4897-97a0-f6d8c4e9ac5b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CoverLetter'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (31/31), done.\u001b[K\n",
            "remote: Total 33 (delta 15), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (33/33), 100.59 KiB | 1.70 MiB/s, done.\n",
            "Resolving deltas: 100% (15/15), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import textwrap\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ],
      "metadata": {
        "id": "At05GNhPPQ-s"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q PyPDF2"
      ],
      "metadata": {
        "id": "4qshbooyX7EJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbddfcbf-2a62-4bfd-83bb-cc79e2035edc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/232.6 kB\u001b[0m \u001b[31m623.9 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/232.6 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m184.3/232.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install docx\n",
        "!pip install fpdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLepXwZwYBfz",
        "outputId": "86f759c6-7a18-47d4-8d64-50c67702025d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting docx\n",
            "  Downloading docx-0.2.4.tar.gz (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m814.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from docx) (4.9.4)\n",
            "Requirement already satisfied: Pillow>=2.0 in /usr/local/lib/python3.10/dist-packages (from docx) (9.4.0)\n",
            "Building wheels for collected packages: docx\n",
            "  Building wheel for docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx: filename=docx-0.2.4-py3-none-any.whl size=53892 sha256=91a2516bee1bf06ccd6435e74fd3bc1c323ddc1385e109dff7d0e349f7b4cb0d\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/f5/1d/e09ba2c1907a43a4146d1189ae4733ca1a3bfe27ee39507767\n",
            "Successfully built docx\n",
            "Installing collected packages: docx\n",
            "Successfully installed docx-0.2.4\n",
            "Collecting fpdf\n",
            "  Downloading fpdf-1.7.2.tar.gz (39 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: fpdf\n",
            "  Building wheel for fpdf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fpdf: filename=fpdf-1.7.2-py2.py3-none-any.whl size=40704 sha256=9864aab44fce1177266f45c43a362142713a479fc7df33dbc6b62d0834835497\n",
            "  Stored in directory: /root/.cache/pip/wheels/f9/95/ba/f418094659025eb9611f17cbcaf2334236bf39a0c3453ea455\n",
            "Successfully built fpdf\n",
            "Installing collected packages: fpdf\n",
            "Successfully installed fpdf-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-docx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIHuTeqilm84",
        "outputId": "eb6cc8e5-9683-4506-c59e-f78801d68764"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.4)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.12.2)\n",
            "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-docx\n",
            "Successfully installed python-docx-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from genai import GenerativeModel\n",
        "from docx import Document\n",
        "from docx.shared import Pt\n",
        "import re\n",
        "import time"
      ],
      "metadata": {
        "id": "a1sqyTAmRfRw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Used to securely store your API key\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "eB61SnIWVKVm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import textwrap\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ],
      "metadata": {
        "id": "-hpD7lN6K1O2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "eyq9gB2IV8E7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel('gemini-1.5-flash')"
      ],
      "metadata": {
        "id": "OdyzB6kgYN9b"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PyPDF2 import PdfReader\n",
        "\n",
        "def load_and_extract_text(file_path):\n",
        "    with open(file_path, 'rb') as file:\n",
        "        pdf_reader = PdfReader(file)\n",
        "        text = \"\"\n",
        "        for page in pdf_reader.pages:\n",
        "            text += page.extract_text()\n",
        "        return text"
      ],
      "metadata": {
        "id": "scs-j7SadNPa"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "yrZFX_ZGCAKu"
      },
      "outputs": [],
      "source": [
        "def generate_cover_letter(model,cv_text, job_description_text):\n",
        "\n",
        "    prompt = f\"\"\"Based on the provided job description and CV, write a concise, compelling and personalized cover letter that highlights relevant skills and experiences.\n",
        "\n",
        "    Job Description:\\n{job_description_text}\\n\\nCV:\\n{cv_text}\\n\\n\n",
        "\n",
        "    Tailor the letter to the specific job requirements and showcase the candidate's match for the position. Be sure to mention specific accomplishments and quantify results whenever possible. Keep the tone professional and precise based on the cv.\n",
        "    As concise as possible no more than 4 sentences. Avoid using adjectives unless neccessary , as less as possible , do not use emotive adjectives in any case, use only factual information based on the cv_text , finalize with best regards, Name where the name of the applicant is taken from the CV\"\"\"\n",
        "    print(\"HERE generate_cover_letter\")\n",
        "    response = model.generate_content(prompt)  # Remove the 'context' argument\n",
        "    print(\"after generate_cover_letter\")\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "job_description = \"\"\" We're seeking an AI Developer to join our team. In this role, you'll leverage artificial intelligence and machine learning techniques to improve the invoice reconciliation process and create a unified data format across various financial systems.\n",
        "\n",
        "Responsibilities:\n",
        "- Develop and implement AI and machine learning models to automate invoice reconciliation\n",
        "- Create intelligent systems to unify diverse invoice data into a standardized format\n",
        "- Design and build natural language processing (NLP) solutions to extract key information from unstructured invoice data\n",
        "- Implement machine learning algorithms to identify patterns, anomalies, and potential errors in financial data\n",
        "- Collaborate with finance and accounting teams to understand business requirements and integrate AI solutions into existing workflows\n",
        "- Continuously improve and optimize AI models based on new data and changing business needs\n",
        "\n",
        "Requirements:\n",
        "- Masters or PhD in Computer Science, Artificial Intelligence, or related field\n",
        "- 3+ years of experience developing AI and machine learning solutions, preferably in finance or accounting domains\n",
        "- Strong programming skills in Python and experience with ML frameworks (e.g., TensorFlow, PyTorch, scikit-learn)\n",
        "- Experience with NLP techniques and text analysis\n",
        "- Familiarity with financial systems, ERP software, and accounting principles\n",
        "- Knowledge of data privacy and security best practices\n",
        "- Excellent problem-solving skills and ability to translate complex business requirements into technical solutions\n",
        "\n",
        "No agencies please.\n",
        "This individual must be available for 30h/week and during UK working hours.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "fh4UxsGzyvCh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_text = load_and_extract_text(\"CoverLetter/Data/CV_GPT_rev.pdf\")"
      ],
      "metadata": {
        "id": "w9qtW_RXdDwD"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "dedzxL_GqtL8",
        "outputId": "bd1e23d6-adc1-4bf5-88da-e72dc765c4aa"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Itay\\nBen-Dan\\nHaarava\\n20,\\nHerzliya\\nP.\\nO.\\nBox\\n5990,\\nHerzliya,\\nIsrael\\n46100\\nCellular:\\n+972544539284\\nEmail:\\nitaybd@gmail.com\\nProfessional\\nSummary\\nFull\\nStack\\nMachine\\nLearning\\nEngineer\\nwith\\nextensive\\nexperience\\nin\\ndata\\nengineering,\\nmodel\\ndevelopment,\\ndeployment,\\nand\\nmaintenance.\\nExpertise\\nin\\nsports,\\nfinance,\\nand\\nrobotics,\\nwith\\na\\nfocus\\non\\nadvanced\\ndata\\nanalytics\\nand\\nmachine\\nlearning,\\nincluding\\nLLMs\\nand\\nmulti-agent\\nsystems.\\nWork\\nExperience\\n2017-Present:\\nMachine\\nLearning\\nand\\nData\\nScience\\nConsultant\\n●\\nDeveloped\\npredictive\\nmodels\\nfrom\\nscratch,\\nincluding\\ndeployment.\\n●\\nConducted\\nexploratory\\ndata\\nanalysis\\nand\\nadvanced\\nfeature\\ngeneration.\\n●\\nIntegrated\\ndata\\nfrom\\nvarious\\nsources\\ninto\\nunified\\nformats.\\n●\\nDeveloped\\npolicy\\ngenerative\\nmodels\\nusing\\nreinforcement\\nlearning.\\n2017-Present:\\nFounder\\nand\\nHead\\nof\\nResearch,\\nFinzor\\nLtd.\\n●\\nDeveloped\\nportfolio\\nmanagement\\nand\\ninvestment\\nanalysis\\ntools.\\n●\\nLed\\na\\nteam\\nto\\ndeliver\\nsoftware\\nproducts\\nfrom\\ndesign\\nto\\nproduction.\\n2016-2017:\\nPrincipal\\nMachine\\nLearning,\\nPalo\\nAlto\\nNetworks\\n●\\nApplied\\nmachine\\nlearning\\nto\\nreverse\\nengineering\\nand\\nmalware\\nanalysis.\\n●\\nCreated\\nadaptive\\nmodels\\nfor\\nupdating\\nanti-malware\\nfilters\\nand\\nclassifiers.\\n2015-2016:\\nSenior\\nData\\nScientist,\\nSparkBeyond\\n●\\nWorked\\non\\nbig\\ndata\\npredictive\\nanalytics\\nand\\nmachine\\nlearning.\\n●\\nApplied\\nautomatic\\nfeature\\ngeneration\\nmethods\\nto\\ntime\\nseries\\nanalysis\\nand\\nreinforcement\\nlearning.\\n2011-2015:\\nSenior\\nQuantitative\\nResearcher,\\nWorldQuant●\\nDeveloped\\nautomated\\ncomputational\\nmethods\\nfor\\nquant-driven\\nstrategies.\\n●\\nApplied\\npredictive\\nanalytics\\nand\\nstatistical\\nmethods\\nacross\\nvarious\\nassets.\\n2010-2011:\\nSenior\\nSoftware\\nEngineer,\\nBroadcom\\n●\\nDesigned\\nnetwork\\nand\\npacket\\nprocessing\\nmethodologies.\\n●\\nImplemented\\nadvanced\\nautomated\\ntesting\\nmethods.\\n2008-2009:\\nFounder,\\nGenous\\nVision\\n●\\nDeveloped\\nalgorithms\\nfor\\nrecognizing\\nanatomies\\nin\\nultrasound\\nimages.\\nEducation\\n2009:\\nPh.D.\\nin\\nMathematics,\\nTechnion,\\nHaifa\\n●\\nTopic:\\nDiscrete\\nGeometry\\n●\\nSupervisor:\\nDr.\\nRom\\nPinchasi\\n2004:\\nM.Sc.\\nin\\nMathematics,\\nTechnion,\\nHaifa\\n●\\nTopic:\\nGame\\nTheory\\n●\\nThesis:\\nTime\\nSharing\\nunder\\nDichotomous\\nPreferences\\n●\\nGrade:\\n95\\n●\\nSupervisor:\\nProf.\\nRon\\nHolzman\\n2002:\\nB.Sc.\\nin\\nMathematics\\nand\\nComputer\\nScience,\\nTechnion,\\nHaifa\\n●\\nCum\\nLaude\\nSkills\\n●\\nProgramming\\nLanguages:\\nPython,\\nR,\\nC++,\\nJava\\n●\\nMachine\\nLearning\\nFrameworks:\\nTensorFlow,\\nPyTorch,\\nScikit-learn\\n●\\nData\\nAnalysis\\nTools:\\nPandas,\\nNumPy,\\nSQL\\n●\\nOther\\nTechnologies:\\nDocker,\\nKubernetes,\\nAWS,\\nGit,\\nLinux\\nProjects\\nTreeModelVis●\\nVisualization\\ntool\\nfor\\ntree-based\\nmodels,\\naiding\\nin\\nunderstanding\\ndecision\\npaths\\nand\\nfeature\\nimportance.\\n●\\nTechnologies\\nUsed:\\nPython,\\nD3.js\\n●\\nGitHub\\nRepository\\nPublications\\n●\\nPoints\\nwith\\nLarge\\nQuadrant\\nDepth.\\nJoCG\\n2(1):\\n128-143\\n(2011)\\n●\\nPoints\\nwith\\nlarge\\nquadrant\\ndepth.\\nSymposium\\non\\nComputational\\nGeometry\\n2010:\\n358-364\\n●\\nOn\\na\\nproblem\\nabout\\nquadrant\\ndepth.\\nComput.\\nGeom.\\n43(6-7):\\n587-592\\n(2010)\\n●\\nPoints\\nwith\\nlarge\\nalphadepth.\\nJ.\\nComb.\\nTheory,\\nSer.\\nA\\n116(3):\\n747-755\\n(2009)\\nContact\\nInformation\\n●\\nEmail:\\nitaybd@gmail.com\\n●\\nLinkedIn:\\nItay\\nBen-Dan\\nLinkedIn\\nProfile\\nThis\\nCV\\nis\\nconcise\\nand\\ntailored,\\nhighlighting\\nkey\\nskills\\nand\\nexperience\\nin\\na\\nclean,\\norganized\\nformat.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_cover_letter(model,cv_text, job_description).text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "xO8AqhoydojT",
        "outputId": "c406afb0-730c-4a29-f1db-683782d27838"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HERE generate_cover_letter\n",
            "after generate_cover_letter\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Dear Hiring Manager,\\n\\nMy extensive experience in developing and deploying AI and machine learning solutions, particularly in finance and data engineering, makes me a strong candidate for the AI Developer position. I have a proven track record of creating predictive models from scratch, including deployment, and integrating data from various sources into unified formats. My expertise in NLP techniques and financial systems, coupled with my familiarity with ML frameworks (TensorFlow, PyTorch, scikit-learn) and data privacy practices, makes me well-suited for this role. I am available for 30 hours per week during UK working hours. \\n\\nBest Regards,\\nItay Ben-Dan \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_key_phrases(model, cover_letter_text, job_description_text, num_phrases=4):\n",
        "    \"\"\"\n",
        "    Extracts key phrases from a cover letter based on their relevance to a job description using Gemini.\n",
        "\n",
        "    Args:\n",
        "        model: The Gemini language model instance.\n",
        "        cover_letter_text: The text of the cover letter.\n",
        "        job_description_text: The text of the job description.\n",
        "        num_phrases: The number of phrases to extract (default is 4).\n",
        "\n",
        "    Returns:\n",
        "        A list of the most important phrases.\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = f\"\"\"Given the following cover letter and job description, identify the {num_phrases} most important words or two-word expressions in the cover letter that are most relevant to the job description.\n",
        "    These words or Two words expression should show professional skills of the candidate they should reflecy the candidate as a doer, if it is an action like developing/programming it should be accompanied with the subject of the action. such as :\n",
        "    developing AI models.\n",
        "\n",
        "    Cover Letter:\n",
        "    {cover_letter_text}\n",
        "\n",
        "    Job Description:\n",
        "    {job_description_text}\n",
        "    \"\"\"\n",
        "    print(\"HERE key phrases\")\n",
        "    response = model.generate_content(prompt)\n",
        "\n",
        "    # Extract key phrases from response\n",
        "    important_phrases = response.text.split('\\n')  # Assuming each phrase is on a new line\n",
        "    print(len(important_phrases))\n",
        "    return important_phrases"
      ],
      "metadata": {
        "id": "hCqxY9clh-rH"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time.sleep(3)\n",
        "job_description = job_description #load_and_extract_text(\"job_description.pdf\")\n",
        "cv_text = load_and_extract_text(\"CoverLetter/Data/CV_GPT_rev.pdf\")\n",
        "cover_letter_text = generate_cover_letter(model,cv_text, job_description).text\n",
        "for k in cover_letter_text.split(\".\"):\n",
        "  print(k)\n",
        "time.sleep(3)\n",
        "key_phrases = extract_key_phrases(model, cover_letter_text, job_description, num_phrases=3)\n",
        "for k in key_phrases:\n",
        "  print(\"#\"*30)\n",
        "  print(k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "CC26_KnJNl7k",
        "outputId": "6fd1a8b2-e5fc-4201-8d8c-52461bed3f9f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HERE generate_cover_letter\n",
            "after generate_cover_letter\n",
            "Dear Hiring Manager,\n",
            "\n",
            "My extensive experience in developing and deploying AI solutions, particularly in finance and data engineering, aligns well with your requirements\n",
            " I have a proven track record of creating and implementing machine learning models for predictive analytics, data unification, and automating processes\n",
            "  My experience with NLP techniques, specifically in building policy generative models using reinforcement learning, is directly applicable to the invoice reconciliation challenge\n",
            "  I am confident I can contribute significantly to your team\n",
            "\n",
            "\n",
            "Best regards,\n",
            "\n",
            "Itay Ben-Dan \n",
            "\n",
            "HERE key phrases\n",
            "6\n",
            "##############################\n",
            "Here are the 3 most important words/phrases from the cover letter that align with the job description, highlighting the candidate's skills and experience:\n",
            "##############################\n",
            "\n",
            "##############################\n",
            "1. **Developing AI models:** This directly matches the core responsibility of the job, showcasing the candidate's ability to build and implement AI solutions. \n",
            "##############################\n",
            "2. **NLP techniques:**  The job description emphasizes NLP skills for invoice data extraction, and the candidate specifically mentions experience with building policy generative models using reinforcement learning, demonstrating relevant expertise.\n",
            "##############################\n",
            "3. **Finance and data engineering:**  The candidate highlights experience in these specific domains, aligning with the job's focus on AI solutions for financial processes and data unification. \n",
            "##############################\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_strings(key_phrases):\n",
        "  R= []\n",
        "  for k in key_phrases:\n",
        "    A = (re.findall('\\*\\*.*?\\*\\*',k))\n",
        "    if len(A)>0:\n",
        "      R += re.findall('[A-Za-z\\ 0-9]+',A[0])\n",
        "  return R"
      ],
      "metadata": {
        "id": "ZPDpn1jp0eS1"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extract_strings(extract_key_phrases(model, cover_letter_text, job_description, num_phrases=3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "5IeUwuSB4tJx",
        "outputId": "3268b0b8-1797-46e7-de6a-4e4bcbffc093"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HERE key phrases\n",
            "6\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Developing AI solutions',\n",
              " 'Building policy generative models',\n",
              " 'Automating processes']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from docx import Document\n",
        "from docx.shared import Pt\n",
        "from docx.oxml.ns import qn\n",
        "from docx.oxml import OxmlElement\n",
        "\n",
        "def bold_strings_in_text(text, bold_strings, output_doc):\n",
        "    # Create a new Document\n",
        "    doc = Document()\n",
        "\n",
        "    # Add the text to the document, with specified strings in bold\n",
        "    para = doc.add_paragraph()\n",
        "    parts = split_text(text, bold_strings)\n",
        "\n",
        "    for part in parts:\n",
        "        if part.lower() in [s.lower() for s in bold_strings]:\n",
        "            run = para.add_run(part)\n",
        "            run.bold = True\n",
        "        else:\n",
        "            para.add_run(part)\n",
        "\n",
        "    # Save the document\n",
        "    doc.save(output_doc)\n",
        "\n",
        "def split_text(text, bold_strings):\n",
        "    import re\n",
        "    pattern = '|'.join(re.escape(s) for s in bold_strings)\n",
        "    parts = re.split(f'({pattern})', text)\n",
        "    print(parts)\n",
        "    return parts\n",
        "\n",
        "# Example usage\n",
        "text = \"This is a sample text. We want some words like sample and words to be bold.\"\n",
        "bold_strings = [\"sample\", \"words\"]\n",
        "bold_strings_in_text(text, bold_strings,\"output.docx\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpV3EAEf5AQG",
        "outputId": "6f24df49-6b78-4a44-c59c-a1a657d18170"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['This is a ', 'sample', ' text. We want some ', 'words', ' like ', 'sample', ' and ', 'words', ' to be bold.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cl_text = generate_cover_letter(model,cv_text, job_description).text\n",
        "strings = extract_strings(extract_key_phrases(model, cl_text, job_description, num_phrases=3))\n",
        "bold_strings_in_text(cl_text, strings, \"test2.docx\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "Tqeq5Cgn5otS",
        "outputId": "e72c9d55-8237-4d80-b66e-2d96c058bdb1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HERE generate_cover_letter\n",
            "after generate_cover_letter\n",
            "HERE key phrases\n",
            "6\n",
            "['Dear Hiring Manager,\\n\\nI am writing to express my strong interest in the AI Developer position at your company. My expertise in developing and deploying AI models, particularly in the financial domain, aligns well with your requirement for automating invoice reconciliation and data standardization. I have a proven track record of success in building predictive models, integrating diverse data sources, and developing ', 'NLP solutions', ' for extracting key information from unstructured data. I am confident that my experience and skills would be a valuable asset to your team. \\n\\nBest regards,\\n\\nItay Ben-Dan \\n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(strings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCzpElqwdp_n",
        "outputId": "49a079fb-971b-4468-e381-b2ee6c078030"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Developing AI models', 'Financial domain', 'NLP solutions']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cl_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "37GpRjmhHvFW",
        "outputId": "5abc515a-17cb-4a88-a71d-08671c9109cd"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Dear Hiring Manager,\\n\\nI am writing to express my strong interest in the AI Developer position at your company. My expertise in developing and deploying AI models, particularly in the financial domain, aligns well with your requirement for automating invoice reconciliation and data standardization. I have a proven track record of success in building predictive models, integrating diverse data sources, and developing NLP solutions for extracting key information from unstructured data. I am confident that my experience and skills would be a valuable asset to your team. \\n\\nBest regards,\\n\\nItay Ben-Dan \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxWAcOH0dcDX",
        "outputId": "fcdf3d4f-732b-4ae1-e345-42bf13e7527f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CoverLetter  output.docx  sample_data  test2.docx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-docx reportlab pypandoc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfIQHI25AyE2",
        "outputId": "259861c9-1770-4c1c-dae7-3877cd9cf7fc"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.10/dist-packages (1.1.2)\n",
            "Collecting reportlab\n",
            "  Downloading reportlab-4.2.2-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting pypandoc\n",
            "  Downloading pypandoc-1.13-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.4)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.12.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from reportlab) (9.4.0)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from reportlab) (5.2.0)\n",
            "Downloading reportlab-4.2.2-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypandoc-1.13-py3-none-any.whl (21 kB)\n",
            "Installing collected packages: reportlab, pypandoc\n",
            "Successfully installed pypandoc-1.13 reportlab-4.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from docx import Document\n",
        "import re\n",
        "import pypandoc\n",
        "from reportlab.lib.pagesizes import letter\n",
        "from reportlab.pdfgen import canvas"
      ],
      "metadata": {
        "id": "asVLIGH_CVwd"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install docx2pdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCfE-HPko4M3",
        "outputId": "581d7452-a256-4d20-dec8-62c45ec1916e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting docx2pdf\n",
            "  Downloading docx2pdf-0.1.8-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from docx2pdf) (4.66.5)\n",
            "Downloading docx2pdf-0.1.8-py3-none-any.whl (6.7 kB)\n",
            "Installing collected packages: docx2pdf\n",
            "Successfully installed docx2pdf-0.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from docx import Document\n",
        "import re\n",
        "from reportlab.lib.pagesizes import letter\n",
        "from reportlab.pdfgen import canvas\n",
        "from io import BytesIO\n"
      ],
      "metadata": {
        "id": "5WKdksutokW3"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_docx_to_pdf(input_docx, output_pdf, title, name):\n",
        "    # Convert docx to PDF using BytesIO to avoid creating temporary files\n",
        "    pdf_buffer = BytesIO()\n",
        "    pdf = canvas.Canvas(pdf_buffer, pagesize=letter)\n",
        "    width, height = letter\n",
        "\n",
        "    # Add title and name\n",
        "    pdf.setFont(\"Helvetica-Bold\", 16)\n",
        "    pdf.drawString(72, height - 72, title)\n",
        "    pdf.setFont(\"Helvetica\", 12)\n",
        "    pdf.drawString(72, height - 92, name)\n",
        "\n",
        "    # Read the docx file and add content to the PDF\n",
        "    doc = Document(input_docx)\n",
        "    text_object = pdf.beginText(72, height - 112)\n",
        "    text_object.setFont(\"Helvetica\", 10)\n",
        "\n",
        "    for para in doc.paragraphs:\n",
        "        for run in para.runs:\n",
        "            if run.bold:\n",
        "                text_object.setFont(\"Helvetica-Bold\", 10)\n",
        "            else:\n",
        "                text_object.setFont(\"Helvetica\", 10)\n",
        "            text_object.textLine(run.text)\n",
        "\n",
        "    pdf.drawText(text_object)\n",
        "    pdf.save()"
      ],
      "metadata": {
        "id": "rQjyQehNCYX3"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name = \"Itay Ben-Dan\"\n",
        "title = \"AI Developer Application\"\n",
        "cl_pdf_name = \"output.docx\"\n",
        "output_doc_name = \"cl_output.pdf\"\n",
        "convert_docx_to_pdf(cl_pdf_name, output_doc_name, title, name)"
      ],
      "metadata": {
        "id": "k1bGwb0pCpsM"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from reportlab.lib.pagesizes import letter\n",
        "from reportlab.pdfgen import canvas\n",
        "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
        "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n",
        "from reportlab.lib.units import inch\n",
        "import re\n",
        "\n",
        "def create_pdf_with_bold_strings(output_pdf, title, name, text, bold_strings):\n",
        "    # Create the PDF document\n",
        "    pdf = SimpleDocTemplate(output_pdf, pagesize=letter)\n",
        "    styles = getSampleStyleSheet()\n",
        "    story = []\n",
        "\n",
        "    # Define custom styles for title and body text\n",
        "    title_style = ParagraphStyle(name='Title', fontSize=16, leading=20, spaceAfter=20, alignment=1)\n",
        "    name_style = ParagraphStyle(name='Name', fontSize=12, leading=14, spaceAfter=14, alignment=1)\n",
        "    body_style = styles['BodyText']\n",
        "    bold_style = ParagraphStyle(name='Bold', parent=styles['BodyText'], fontName='Helvetica-Bold')\n",
        "\n",
        "    # Add title\n",
        "    story.append(Paragraph(title, title_style))\n",
        "\n",
        "    # Add name\n",
        "    story.append(Paragraph(name, name_style))\n",
        "    story.append(Spacer(1, 12))\n",
        "\n",
        "    # Process and add the main text with bold strings\n",
        "    parts = split_text(text, bold_strings)\n",
        "    for part in parts:\n",
        "        if any(re.fullmatch(re.escape(b), part, re.IGNORECASE) for b in bold_strings):\n",
        "            story.append(Paragraph(part, bold_style))\n",
        "        else:\n",
        "            story.append(Paragraph(part, body_style))\n",
        "\n",
        "    # Build the PDF\n",
        "    pdf.build(story)\n",
        "\n",
        "def split_text(text, bold_strings):\n",
        "    pattern = '|'.join(re.escape(s) for s in bold_strings)\n",
        "    parts = re.split(f'({pattern})', text, flags=re.IGNORECASE)\n",
        "    return parts\n",
        "\n",
        "# Example usage\n",
        "cv_text = \"John Doe\"\n",
        "text = \"\"\"Dear Hiring Manager,\n",
        "\n",
        "I am writing to express my strong interest in the AI Developer position at your company. My extensive experience in developing and deploying AI solutions, particularly in finance and data analytics, aligns well with your requirements. My accomplishments include building predictive models from scratch, integrating data from diverse sources into unified formats, and creating adaptive models for updating anti-malware filters. I am confident that my skills and experience would be a valuable asset to your team.\n",
        "\"\"\"\n",
        "bold_strings = [\"developing and deploying AI solutions\", \"integrating data from diverse sources\", \"creating adaptive models\"]\n",
        "output_pdf = \"output_professional.pdf\"\n",
        "title = \"AI Developer Application\"\n",
        "\n",
        "create_pdf_with_bold_strings(output_pdf, title, cv_text, text, bold_strings)\n"
      ],
      "metadata": {
        "id": "V5Nww8qVsII_"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "!git clone https://github.com/openai/openai-quickstart-node.git\n",
        "!pip install openai\n",
        "!pip install tiktoken\n",
        "!pip install python-dotenv\n",
        "import os\n",
        "os.chdir(\"openai-quickstart-node\")\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "J7_M39b1Nhmh",
        "outputId": "1be41284-a69e-4b80-d0f5-07714674a017"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n!git clone https://github.com/openai/openai-quickstart-node.git\\n!pip install openai\\n!pip install tiktoken\\n!pip install python-dotenv\\nimport os\\nos.chdir(\"openai-quickstart-node\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUboZeAQMVUc",
        "outputId": "c6277dba-e17f-44bd-f940-c0353fcf518d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.5)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.10.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.7.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import sys\n",
        "from google.colab import userdata\n",
        "\n",
        "OPENAI_API_KEY=userdata.get('OPENAI_API_KEY2')\n",
        "\n",
        "openai.api_key  = OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "rFaLFWH-5a4y"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#prompt = f\"\"\"Based on the provided job description and CV, write a concise, compelling and personalized cover letter that highlights relevant skills and experiences.\n",
        "\n",
        "#    Job Description:\\n{job_description_text}\\n\\nCV:\\n{cv_text}\\n\\n\n",
        "\n",
        "#    Tailor the letter to the specific job requirements and showcase the candidate's match for the position. Be sure to mention specific accomplishments and quantify results whenever possible. Keep the tone professional and precise based on the cv.\n",
        "#    As concise as possible no more than 4 sentences. Avoid using adjectives unless neccessary , as less as possible , do not use emotive adjectives in any case, use only factual information based on the cv_text , finalize with best regards, Name where the name of the applicant is taken from the CV\"\"\"\n"
      ],
      "metadata": {
        "id": "siwXieTaJhUf"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "def generate_improved_text(prompt):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a highly experienced career coach and recruiter. Your job is to critically evaluate cover letters based on job descriptions, resumes (CVs), and the expected professional standards for the role. You provide detailed feedback on various aspects of the cover letter.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    return response['choices'][0]['message']['content'].strip()\n",
        "\n",
        "# Function to create the prompt\n",
        "def create_critique_prompt(cover_letter_pdf, cv_text, job_description):\n",
        "    prompt = f\"\"\"\n",
        "    I need you to critique a cover letter that was submitted for an AI Developer role. The cover letter is provided as a PDF file, and I'll summarize its content below. The candidate's resume (CV) and the job description are also provided. Please evaluate the cover letter based on the following criteria:\n",
        "\n",
        "    1. **Relevance to the Job**: Does the cover letter effectively address the specific responsibilities and requirements of the job as described in the job description?\n",
        "    2. **Form and Structure**: Is the cover letter well-organized and professionally formatted? Does it follow standard cover letter conventions?\n",
        "    3. **Reliability**: Does the cover letter convey a sense of reliability and trustworthiness? Is it free from errors and inconsistencies?\n",
        "    4. **Professional Matching**: Does the cover letter demonstrate that the candidate's skills, experience, and background match the job's requirements?\n",
        "    5. **Overall Impression**: How compelling is the cover letter in making the case that the candidate is a strong fit for the role?\n",
        "\n",
        "    After critiquing the cover letter on these criteria, please provide an overall grade on a scale of 1-10, where 10 is the best.\n",
        "\n",
        "    Here are the details:\n",
        "\n",
        "    **Cover Letter Summary**:\n",
        "    (Provide a summary of the content of the cover letter extracted from the PDF.)\n",
        "\n",
        "    **Resume (CV) Text**:\n",
        "    {cv_text}\n",
        "\n",
        "    **Job Description**:\n",
        "    {job_description}\n",
        "\n",
        "    Please provide a detailed critique with specific points for improvement and an overall grade in the format Grade : **NUMBER**  where number is on the scale of 1-10.\n",
        "    \"\"\"\n",
        "    return generate_improved_text(prompt)"
      ],
      "metadata": {
        "id": "ehj8i6iXlwPx"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from reportlab.lib.pagesizes import letter\n",
        "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n",
        "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
        "\n",
        "# Set your OpenAI API key\n",
        "\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "\n",
        "# Function to generate improved text using OpenAI API\n",
        "def generate_improved_text(prompt):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    return response['choices'][0]['message']['content'].strip()\n",
        "\n",
        "# Function to improve the cover letter\n",
        "def improve_cover_letter(CV_text, cover_letter,job_description_text, critique = \"\"):\n",
        "    if critique == \"\":\n",
        "      critique = create_critique_prompt(cover_letter, cv_text, job_description_text)\n",
        "    #prompt = f\"Given the following cover letter and critique, generate an improved version of the cover letter:\\n\\nCover Letter:\\n{cover_letter}\\n\\nCritique:\\n{critique}\\n\\nImproved Cover Letter:\"\n",
        "    prompt = f\"\"\"Based on the provided job description, original cover letter (the one that the critique refers to), and CV, write a concise, exact, factual and personalized cover letter that highlights relevant skills and experiences. the resulting letter should take into account the critique and improve accordingly\n",
        "\n",
        "\n",
        "   Job Description:\\n{job_description_text}\\n\\nCV:\\n{CV_text}\\n\\nCritique:\\n\\ncover_letter:\\n{cover_letter}\\n\\nCritique:\\n{critique}\\n\\n\n",
        "\n",
        "    Tailor the letter to the specific job requirements and showcase the candidate's match for the position. Be sure to mention specific accomplishments and quantify results whenever possible. Keep the tone professional and precise based on the cv.\n",
        "   As concise as possible no more than 4 sentences. Avoid using adjectives unless neccessary , as less as possible , do not use emotive adjectives in any case, use only factual information based on the cv_text , finalize with best regards, Name where the name of the applicant is taken from the CV\"\"\"\n",
        "\n",
        "    return generate_improved_text(prompt)\n",
        "\n",
        "# Function to improve the CV\n",
        "def improve_cv(cv_text, critique):\n",
        "    prompt = f\"Given the following CV and critique, generate an improved version of the CV:\\n\\nCV:\\n{cv_text}\\n\\nCritique:\\n{critique}\\n\\nImproved CV:\"\n",
        "    return generate_improved_text(prompt)\n",
        "\n",
        "# Function to create a PDF from text\n",
        "def create_pdf(output_pdf, title, name, text):\n",
        "    print(output_pdf)\n",
        "    pdf = SimpleDocTemplate(output_pdf, pagesize=letter)\n",
        "    styles = getSampleStyleSheet()\n",
        "    story = []\n",
        "\n",
        "    # Define custom styles for title and body text\n",
        "    title_style = ParagraphStyle(name='Title', fontSize=16, leading=20, spaceAfter=20, alignment=1)\n",
        "    name_style = ParagraphStyle(name='Name', fontSize=12, leading=14, spaceAfter=14, alignment=1)\n",
        "    body_style = styles['BodyText']\n",
        "    bold_style = ParagraphStyle(name='Bold', parent=styles['BodyText'], fontName='Helvetica-Bold')\n",
        "\n",
        "    # Add title\n",
        "    story.append(Paragraph(title, title_style))\n",
        "\n",
        "    # Add name\n",
        "    story.append(Paragraph(name, name_style))\n",
        "    story.append(Spacer(1, 12))\n",
        "\n",
        "    # Process and add the main text\n",
        "    paragraphs = text.split(\"\\n\\n\")\n",
        "    for para in paragraphs:\n",
        "        story.append(Paragraph(para.replace('\\n', '<br/>'), body_style))\n",
        "        story.append(Spacer(1, 12))\n",
        "\n",
        "    # Build the PDF\n",
        "    pdf.build(story)\n",
        "\n"
      ],
      "metadata": {
        "id": "fJTJ--QxtJRz"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "#generate_cover_letter\n",
        "#extract_key_phrases\n",
        "#create_pdf_with_bold_strings(output_pdf, title, cv_text, text, bold_strings)\n",
        "#improve_cover_letter\n",
        "#improved_cover_letter\n",
        "#extract_key_phrases(model, cover_letter_text, job_description, num_phrases=3)\n",
        "\n",
        "cv_text = load_and_extract_text(\"CoverLetter/Data/CV_GPT_rev.pdf\")\n",
        "cover_letter_text = generate_cover_letter(model,cv_text, job_description).text\n",
        "bold_strings = extract_strings(extract_key_phrases(model, cover_letter_text, job_description, num_phrases=3))\n",
        "create_pdf_with_bold_strings(output_pdf, title, cv_text, text, bold_strings)\n",
        "improved_cover_letter = improve_cover_letter(cv_text,cover_letter_text,job_description)\n",
        "#improved_cv = improve_cv(original_cv, cv_critique)\n",
        "\n",
        "#job_description"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "Z5Gq7NGyUIUd",
        "outputId": "533776ce-2b42-4368-c65a-ebc811433e0f"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HERE generate_cover_letter\n",
            "after generate_cover_letter\n",
            "HERE key phrases\n",
            "6\n",
            "CPU times: user 464 ms, sys: 19.3 ms, total: 483 ms\n",
            "Wall time: 23.1 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "critique = create_critique_prompt( improved_cover_letter , cv_text, job_description)\n",
        "critique"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "zxZXXkHytlTA",
        "outputId": "af6dbe8c-047b-4cb9-b492-86437607c546"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"### Cover Letter Critique\\n\\n#### Cover Letter Summary\\n\\nThe cover letter starts with an enthusiastic introduction where the candidate, Itay Ben-Dan, expresses his fervent interest in the AI Developer position. He briefly highlights his extensive experience in machine learning and artificial intelligence, stressing his expertise in financial applications. Specific projects and roles from his career are referenced to demonstrate his qualifications. He aligns his skills to the job responsibilities and concludes by emphasizing his eagerness to contribute to the team, while expressing his readiness to discuss his fit for the role in detail.\\n\\n#### Evaluation Criteria\\n\\n1. **Relevance to the Job**:\\n   - **Strengths**: The candidate clearly articulates his experience aligns with the job requirements. For example, his work on model development and deployment resonates well with the responsibilities of developing and implementing AI models to automate invoice reconciliation.\\n   - **Areas for Improvement**: More specific examples or anecdotes related to invoice reconciliation or financial systems would have strengthened the alignment with the job’s responsibilities.\\n\\n2. **Form and Structure**:\\n   - **Strengths**: The cover letter is organized logically, starting with an introduction, followed by a middle segment that details relevant professional experiences, and concluding with a closing paragraph. It adheres to standard cover letter conventions.\\n   - **Areas for Improvement**: A brief mentioning of the company’s name and why the candidate is particularly interested in this company would make a positive impact. The letter could also be more visually appealing with clear headings or bullet points to highlight specific qualifications.\\n\\n3. **Reliability**:\\n   - **Strengths**: The cover letter is written in a professional tone and is free from grammar or typographical errors, which conveys a sense of reliability and thoroughness.\\n   - **Areas for Improvement**: While it is free from errors, the cover letter feels somewhat generic. Customization for the specific role and company would showcase a stronger commitment and attention to detail.\\n\\n4. **Professional Matching**:\\n   - **Strengths**: Itay's experience in machine learning, development roles, and leadership positions is evident. His academic background (Ph.D. in Mathematics) satisfies the educational requirements.\\n   - **Areas for Improvement**: While his CV shows relevant experience, the cover letter could specify more about his direct experiences in NLP and working with financial data/systems to match the job requirements better.\\n\\n5. **Overall Impression**:\\n   - **Strengths**: The candidate demonstrates a solid background and seems genuinely interested in the role. Uses professional language and organization effectively.\\n   - **Areas for Improvement**: More specific examples of his past work relevant to invoice reconciliation, NLP in financial data, and collaboration with finance teams would significantly boost the compelling nature of the cover letter.\\n\\n#### Specific Points for Improvement\\n\\n- **Customization**: Include the company’s name and why Itay is interested in this particular position and organization.\\n- **Concrete Examples**: Provide more detailed examples or case studies of past experiences closely related to invoice reconciliation or NLP in financial contexts.\\n- **Visual Appeal**: Use clear headings or bullet points to structure important qualifications and experiences, making it easier for the reader to navigate.\\n- **Explicit Matching**: Clearly outline how his skills in NLP, financial systems, and ML frameworks like TensorFlow/PyTorch match the job requirements.\\n\\n### Overall Grade: **7**\\n\\nWhile Itay Ben-Dan’s cover letter demonstrates a strong professional background and enthusiasm, it lacks specific, tailored examples that directly match the job requirements and responsibilities. Enhancing the letter with detailed, relevant experiences, and a more customized tone could elevate its impact significantly.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "for ii in range(10):\n",
        "  grade = float(re.findall(\"[0-9\\.]+\",re.findall(\"Overall Grade: \\*\\*[0-9\\.]+\",critique)[0] )[0])\n",
        "  \"\"\"\n",
        "  except :\n",
        "    print(critique)\n",
        "    #critique = create_critique_prompt( improved_cover_letter , cv_text, job_description\n",
        "  \"\"\"\n",
        "  print(grade)\n",
        "  if grade < 9:\n",
        "    improved_cover_letter = improve_cover_letter(cv_text,cover_letter_text,job_description, critique)\n",
        "    critique = create_critique_prompt( improved_cover_letter , cv_text, job_description)\n",
        "\n",
        "print(critique)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "aTYYDLg9xPVt",
        "outputId": "0aae8da1-dad4-48bb-d3c1-0b8ef29ac16f"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7.0\n",
            "7.0\n",
            "8.0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-2c82c620d36d>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mgrade\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[0-9\\.]+\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Overall Grade: \\*\\*[0-9\\.]+\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcritique\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \"\"\"\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "float(re.findall(\"[0-9\\.]+\",re.findall(\"Grade: **[0-9\\.]+\",critique)[-1] )[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "1ItGZvIh71mx",
        "outputId": "246aedf8-9a63-410c-b7ad-7c3635d025a7"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "multiple repeat at position 8",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-d8858a7d848c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[0-9\\.]+\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Grade: **[0-9\\.]+\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcritique\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.10/re.py\u001b[0m in \u001b[0;36mfindall\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     Empty matches are included in the result.\"\"\"\n\u001b[0;32m--> 240\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfinditer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/re.py\u001b[0m in \u001b[0;36m_compile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msre_compile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"first argument must be string or compiled pattern\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msre_compile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0m_MAXCACHE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/sre_compile.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(p, flags)\u001b[0m\n\u001b[1;32m    786\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msre_parse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    789\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/sre_parse.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(str, flags, state)\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 955\u001b[0;31m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parse_sub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mSRE_FLAG_VERBOSE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    956\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mVerbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m         \u001b[0;31m# the VERBOSE flag was switched on inside the pattern.  to be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/sre_parse.py\u001b[0m in \u001b[0;36m_parse_sub\u001b[0;34m(source, state, verbose, nested)\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m         itemsappend(_parse(source, state, verbose, nested + 1,\n\u001b[0m\u001b[1;32m    445\u001b[0m                            not nested and not items))\n\u001b[1;32m    446\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msourcematch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"|\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/sre_parse.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(source, state, verbose, nested, first)\u001b[0m\n\u001b[1;32m    670\u001b[0m                                    source.tell() - here + len(this))\n\u001b[1;32m    671\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_REPEATCODES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m                 raise source.error(\"multiple repeat\",\n\u001b[0m\u001b[1;32m    673\u001b[0m                                    source.tell() - here + len(this))\n\u001b[1;32m    674\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mSUBPATTERN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: multiple repeat at position 8"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6nxdghNH9Z-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "critique"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "PcqD6okh8TUj",
        "outputId": "635174d1-fb2a-4cbf-94ed-bdc7a2f2d4ef"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Based on the given summary and materials, here is the detailed critique of the cover letter:\\n\\n### 1. Relevance to the Job:\\n\\nThe cover letter highlights the candidate's extensive experience in AI and machine learning, which addresses the job’s core requirements. The candidate mentions specific projects and achievements that align well with responsibilities like developing AI models and unifying diverse data formats. However, the cover letter could better address the specifics of the job requirements, such as direct experience with NLP techniques for invoice data and financial systems.\\n\\n### 2. Form and Structure:\\n\\nThe cover letter is professionally formatted and follows standard cover letter conventions with a clear introduction, body, and conclusion. It opens with a strong statement of interest in the AI Developer role and summarizes relevant career highlights. However, there could be more emphasis on specific job requirements, with concrete examples tied to each point.\\n\\n### 3. Reliability:\\n\\nThe cover letter is free from grammatical errors, which conveys reliability and attention to detail. The tone is professional, and the information presented is consistent with the resume. There are no inconsistencies that would raise concerns about the candidate’s trustworthiness.\\n\\n### 4. Professional Matching:\\n\\nThe cover letter effectively demonstrates that the candidate's skills and background match the job requirements. It includes relevant work experience, such as the development of predictive models and data integration from various sources. The mention of experience in the financial domain (through roles at Finzor Ltd. and WorldQuant) and machine learning expertise (reinforcement learning, generative models) shows alignment with the job’s needs. However, a more detailed discussion of the candidate's experience with NLP and financial data would enhance this alignment further.\\n\\n### 5. Overall Impression:\\n\\nThe cover letter presents the candidate as a strong fit for the AI Developer role, particularly in the area of machine learning and data integration. The candidate's enthusiasm for the position and clear articulation of relevant experience make a compelling case. However, reinforcing specific details about how previous work directly aligns with the job responsibilities would make the cover letter even more compelling.\\n\\n### Points for Improvement:\\n\\n1. **Detail Specific NLP and Financial Systems Experience:**\\n   - Provide more concrete examples of experience with NLP and unstructured data analysis. Clearly connect these examples to the job’s requirement for extracting key information from invoices.\\n   - Discuss familiarity with financial systems and accounting principles in more detail.\\n\\n2. **Match Job Requirements Explicitly:**\\n   - Explicitly mention the alignment with each of the job's responsibilities and requirements. For instance, how experience at Palo Alto Networks or Finzor Ltd. directly translates to automating invoice reconciliation or identifying financial anomalies.\\n\\n3. **Highlight Collaborative Efforts:**\\n   - Emphasize examples of collaboration with finance or other departments to illustrate the candidate’s ability to work with cross-functional teams, which is critical for this role.\\n\\n4. **Showcases Problem-Solving Skills:**\\n   - Provide a specific example or case study that showcases problem-solving skills relevant to the job's context (e.g., resolving a major data integration challenge or identifying significant anomalies).\\n\\n### Overall Grade:\\n\\nGrade: **8**\\n\\nThis cover letter is very strong, but with the suggested improvements, it could be even more tailored to the job at hand and demonstrate an even clearer alignment with the specific role requirements.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grade = int(re.findall(\"[0-9]+\",re.findall(\"Grade: \\*\\*[0-9]+\\*\\*\",critique)[0] )[0])\n",
        "grade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Z-3WvPvxxTk",
        "outputId": "a8c59bf3-b95f-4e1d-93cc-131da26b684d"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cover_letter_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "jn-QVW6JGmBz",
        "outputId": "c863e813-7ba8-46f8-db78-4c8d914e81ba"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Dear Hiring Manager,\\n\\nI am writing to express my interest in the AI Developer position at your company.  My expertise in developing and deploying machine learning models, particularly in the finance domain, aligns well with the requirements of this role. My experience includes developing predictive models, integrating data from diverse sources, and creating NLP solutions for extracting key information from unstructured data. I am confident I can contribute significantly to your team's efforts to automate invoice reconciliation and unify financial data. \\n\\nBest regards,\\n\\nItay Ben-Dan \\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "improved_cover_letter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "C2ICt3nc7zs7",
        "outputId": "b42ad29e-216f-474d-b51e-a861b51806db"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Dear Hiring Team,\\n\\nAs a passionate Full Stack Machine Learning Engineer with a PhD in Mathematics, I am excited about the prospect of contributing to your team as an AI Developer. I bring the requisite 3+ years of AI and machine learning development experience to this role. At Finzor Ltd., I led the creation of investment analysis tools and implemented machine learning methods to unify diversified data formats, a key requirement in your job description.\\n\\nApplying my robust Python programming skills and proficiency in TensorFlow, PyTorch, and scikit-learn, I developed predictive models at Palo Alto Networks that increased detection of malware variations by 20%. My NLP experience aligns with your need for designing solutions to extract information from unstructured invoice data. I am confident my skills and experiences make me a strong fit for improving your invoice reconciliation process.\\n\\nBest Regards,\\n\\nItay Ben-Dan'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "job_description"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "nM6SwAu_cR_D",
        "outputId": "6c1e83b6-fe66-446c-8c7b-644263ca50e2"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" We're seeking an AI Developer to join our team. In this role, you'll leverage artificial intelligence and machine learning techniques to improve the invoice reconciliation process and create a unified data format across various financial systems.\\n\\nResponsibilities:\\n- Develop and implement AI and machine learning models to automate invoice reconciliation\\n- Create intelligent systems to unify diverse invoice data into a standardized format\\n- Design and build natural language processing (NLP) solutions to extract key information from unstructured invoice data\\n- Implement machine learning algorithms to identify patterns, anomalies, and potential errors in financial data\\n- Collaborate with finance and accounting teams to understand business requirements and integrate AI solutions into existing workflows\\n- Continuously improve and optimize AI models based on new data and changing business needs\\n\\nRequirements:\\n- Masters or PhD in Computer Science, Artificial Intelligence, or related field\\n- 3+ years of experience developing AI and machine learning solutions, preferably in finance or accounting domains\\n- Strong programming skills in Python and experience with ML frameworks (e.g., TensorFlow, PyTorch, scikit-learn)\\n- Experience with NLP techniques and text analysis\\n- Familiarity with financial systems, ERP software, and accounting principles\\n- Knowledge of data privacy and security best practices\\n- Excellent problem-solving skills and ability to translate complex business requirements into technical solutions\\n\\nNo agencies please.\\nThis individual must be available for 30h/week and during UK working hours.\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "name = improved_cover_letter.split(\"\\n\")[-1]\n",
        "target_pdf_file = \"cover_letter_improved2.pdf\"\n",
        "title = (\"Cover Letter\")\n",
        "create_pdf(target_pdf_file, title, name,improved_cover_letter )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ww8IsHlNWRuZ",
        "outputId": "03c17ae9-f2ca-4615-f9ab-33d4f087b723"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cover_letter_improved2.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Example usage\n",
        "\n",
        "critique_prompt = create_critique_prompt(cover_letter_text, original_cv, job_description)\n",
        "response = generate_improved_text(critique_prompt)\n",
        "\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edrKUA7V_-Nu",
        "outputId": "496c31c8-b442-42ee-d755-99def85f1b8b"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Cover Letter Summary**:\n",
            "\n",
            "I apologize, but a summary of the cover letter isn't provided for critique. However, using only the information above, let's evaluate the CV and how it can cater to the AI Developer role.\n",
            "\n",
            "1. **Relevance to the Job**:\n",
            "The candidate has broad experience in machine learning, data science, and analytics which correspond to the responsibilities of the AI Developer role. However, the CV lacks a direct connection to the invoice reconciliation and financial domain requirements specified in the job description. The candidate does have some finance-related experience at Finzor Ltd., but it's crucial to highlight the relevance of this experience to the job at hand.\n",
            "\n",
            "2. **Form and Structure**.\n",
            "The CV is well-structured, with a clear work history timeline and articulation of tasks performed at each job. The education history, skills, projects, and publications segments are also well-organized. What's missing is a professional summary or objective that ties the candidate's varied experiences to their goal in the AI developer role.\n",
            "\n",
            "3. **Reliability**:\n",
            "The information seems reliable given the diverse roles the candidate has filled and their steady career trajectory. Based on what's provided, the CV appears to be free from errors and inconsistencies.\n",
            "\n",
            "4. **Professional Matching**: \n",
            "The candidate demonstrates key skills (Python, ML frameworks, etc.) required for the job. On another note, experience with NLP, understanding of accounting principles, and familiarity with financial systems isn't explicit. Addressing these job requirements specifically would improve the match.\n",
            "\n",
            "5. **Overall Impression**: \n",
            "The candidate definitely comes across as a skilled and experienced machine learning professional. However, the CV needs to better call out how the candidate's background matches the specific responsibilities and requirements of the AI Developer role described.\n",
            "\n",
            "**Grade on a 10 Point Scale : 6/10**\n",
            "\n",
            "To improve, the candidate should:\n",
            "- Tailor the resume to highlight relevant finance and accounting-related experiences and projects.\n",
            "- Mention experiences (demonstrable with results) that align with responsibilities, especially focusing on NLP and working with financial systems.\n",
            "- Probably condense the experience to focus on the most important and relevant roles.\n",
            "- Consider including a summary or objective statement to clearly establish their intent for applying to this role.\n",
            "- If possible, expand on roles/projects that involved working directly with stakeholders, as the ability to \"collaborate with finance and accounting teams\" is a requirement.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doFW0YfLfMyK",
        "outputId": "d5fadc16-5bea-4ea4-fe75-3b1f4ea34d87"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CoverLetter\t\t    improved_cover_letter.pdf  output.docx\t\tsample_data\n",
            "cover_letter_improved2.pdf  improved_cv.pdf\t       output_professional.pdf\ttest2.docx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jBi2ecMMWVHG"
      },
      "execution_count": 50,
      "outputs": []
    }
  ]
}