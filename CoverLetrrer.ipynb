{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPpqz3MNehl3C8FjxyezmRT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bdi2357/CoverLetter/blob/main/CoverLetrrer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U google-generativeai"
      ],
      "metadata": {
        "id": "hTAXNfaoRqDr"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/bdi2357/CoverLetter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0bLtjxrR_Ya",
        "outputId": "d492ba0f-20b5-446b-ac49-c05bd4feebdc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CoverLetter'...\n",
            "remote: Enumerating objects: 24, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (22/22), done.\u001b[K\n",
            "remote: Total 24 (delta 8), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (24/24), 84.11 KiB | 16.82 MiB/s, done.\n",
            "Resolving deltas: 100% (8/8), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import textwrap\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ],
      "metadata": {
        "id": "At05GNhPPQ-s"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q PyPDF2"
      ],
      "metadata": {
        "id": "4qshbooyX7EJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ea57c6e-655c-47b7-f209-c0dde271dad7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install docx\n",
        "!pip install fpdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLepXwZwYBfz",
        "outputId": "4e432f8d-7ba1-47bc-cce6-eaa5856630f4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting docx\n",
            "  Downloading docx-0.2.4.tar.gz (54 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/54.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from docx) (4.9.4)\n",
            "Requirement already satisfied: Pillow>=2.0 in /usr/local/lib/python3.10/dist-packages (from docx) (9.4.0)\n",
            "Building wheels for collected packages: docx\n",
            "  Building wheel for docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx: filename=docx-0.2.4-py3-none-any.whl size=53894 sha256=5c8ff149c93984de5796f761bf717d71a25006b5c3cd1bb8e2066779d5be489f\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/f5/1d/e09ba2c1907a43a4146d1189ae4733ca1a3bfe27ee39507767\n",
            "Successfully built docx\n",
            "Installing collected packages: docx\n",
            "Successfully installed docx-0.2.4\n",
            "Collecting fpdf\n",
            "  Downloading fpdf-1.7.2.tar.gz (39 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: fpdf\n",
            "  Building wheel for fpdf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fpdf: filename=fpdf-1.7.2-py2.py3-none-any.whl size=40704 sha256=807ddede081199ea7d02174eb5bff47fb34b9fc0e9de1da6f1261a45ac2e126a\n",
            "  Stored in directory: /root/.cache/pip/wheels/f9/95/ba/f418094659025eb9611f17cbcaf2334236bf39a0c3453ea455\n",
            "Successfully built fpdf\n",
            "Installing collected packages: fpdf\n",
            "Successfully installed fpdf-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-docx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIHuTeqilm84",
        "outputId": "0d859c62-8f87-4939-8e4b-9a11e75cd2b1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.4)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.12.2)\n",
            "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/244.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-docx\n",
            "Successfully installed python-docx-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from genai import GenerativeModel\n",
        "from docx import Document\n",
        "from docx.shared import Pt\n",
        "import re\n",
        "import time"
      ],
      "metadata": {
        "id": "a1sqyTAmRfRw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Used to securely store your API key\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "eB61SnIWVKVm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import textwrap\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ],
      "metadata": {
        "id": "-hpD7lN6K1O2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "eyq9gB2IV8E7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel('gemini-1.5-flash')"
      ],
      "metadata": {
        "id": "OdyzB6kgYN9b"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PyPDF2 import PdfReader\n",
        "\n",
        "def load_and_extract_text(file_path):\n",
        "    with open(file_path, 'rb') as file:\n",
        "        pdf_reader = PdfReader(file)\n",
        "        text = \"\"\n",
        "        for page in pdf_reader.pages:\n",
        "            text += page.extract_text()\n",
        "        return text"
      ],
      "metadata": {
        "id": "scs-j7SadNPa"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "yrZFX_ZGCAKu"
      },
      "outputs": [],
      "source": [
        "def generate_cover_letter(model,cv_text, job_description_text):\n",
        "\n",
        "    prompt = f\"\"\"Based on the provided job description and CV, write a compelling and personalized cover letter that highlights relevant skills and experiences.\n",
        "\n",
        "    Job Description:\\n{job_description_text}\\n\\nCV:\\n{cv_text}\\n\\n\n",
        "\n",
        "    Tailor the letter to the specific job requirements and showcase the candidate's enthusiasm for the position. Be sure to mention specific accomplishments and quantify results whenever possible. Keep the tone professional and engaging.\n",
        "    As concise as possible no more than 4 sentences. Avoid using adjectives unless neccessary , as less as possible , do not use emotive adjectives in any case, use only factual information based on the cv_text\"\"\"\n",
        "    print(\"HERE\")\n",
        "    response = model.generate_content(prompt)  # Remove the 'context' argument\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "job_description = \"\"\" We're seeking an AI Developer to join our team. In this role, you'll leverage artificial intelligence and machine learning techniques to improve the invoice reconciliation process and create a unified data format across various financial systems.\n",
        "\n",
        "Responsibilities:\n",
        "- Develop and implement AI and machine learning models to automate invoice reconciliation\n",
        "- Create intelligent systems to unify diverse invoice data into a standardized format\n",
        "- Design and build natural language processing (NLP) solutions to extract key information from unstructured invoice data\n",
        "- Implement machine learning algorithms to identify patterns, anomalies, and potential errors in financial data\n",
        "- Collaborate with finance and accounting teams to understand business requirements and integrate AI solutions into existing workflows\n",
        "- Continuously improve and optimize AI models based on new data and changing business needs\n",
        "\n",
        "Requirements:\n",
        "- Masters or PhD in Computer Science, Artificial Intelligence, or related field\n",
        "- 3+ years of experience developing AI and machine learning solutions, preferably in finance or accounting domains\n",
        "- Strong programming skills in Python and experience with ML frameworks (e.g., TensorFlow, PyTorch, scikit-learn)\n",
        "- Experience with NLP techniques and text analysis\n",
        "- Familiarity with financial systems, ERP software, and accounting principles\n",
        "- Knowledge of data privacy and security best practices\n",
        "- Excellent problem-solving skills and ability to translate complex business requirements into technical solutions\n",
        "\n",
        "No agencies please.\n",
        "This individual must be available for 30h/week and during UK working hours.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "fh4UxsGzyvCh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_text = load_and_extract_text(\"CoverLetter/Data/CV_GPT_rev.pdf\")"
      ],
      "metadata": {
        "id": "w9qtW_RXdDwD"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_cover_letter(model,cv_text, job_description).text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "xO8AqhoydojT",
        "outputId": "e2a46322-4c0e-446d-faec-499de5791bbf"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HERE\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Dear Hiring Manager,\\n\\nI am writing to express my keen interest in the AI Developer position at your company. With over 6 years of experience developing and deploying machine learning solutions, particularly in finance and data analysis, I am confident in my ability to contribute significantly to your team. My expertise in NLP, financial data analysis, and experience in building predictive models from scratch, including deployment, aligns perfectly with the requirements of this role. I am eager to leverage my skills to automate invoice reconciliation, standardize data formats, and enhance your company's financial processes. \\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_key_phrases(model, cover_letter_text, job_description_text, num_phrases=4):\n",
        "    \"\"\"\n",
        "    Extracts key phrases from a cover letter based on their relevance to a job description using Gemini.\n",
        "\n",
        "    Args:\n",
        "        model: The Gemini language model instance.\n",
        "        cover_letter_text: The text of the cover letter.\n",
        "        job_description_text: The text of the job description.\n",
        "        num_phrases: The number of phrases to extract (default is 4).\n",
        "\n",
        "    Returns:\n",
        "        A list of the most important phrases.\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = f\"\"\"Given the following cover letter and job description, identify the {num_phrases} most important words or two-word expressions in the cover letter that are most relevant to the job description.\n",
        "    These words or Two words expression should show professional skills of the candidate they should reflecy the candidate as a doer, if it is an action like developing/programming it should be accompanied with the subject of the action. such as :\n",
        "    developing AI models.\n",
        "\n",
        "    Cover Letter:\n",
        "    {cover_letter_text}\n",
        "\n",
        "    Job Description:\n",
        "    {job_description_text}\n",
        "    \"\"\"\n",
        "    print(\"HERE\")\n",
        "    response = model.generate_content(prompt)\n",
        "\n",
        "    # Extract key phrases from response\n",
        "    important_phrases = response.text.split('\\n')  # Assuming each phrase is on a new line\n",
        "    return important_phrases"
      ],
      "metadata": {
        "id": "hCqxY9clh-rH"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time.sleep(3)\n",
        "job_description = job_description #load_and_extract_text(\"job_description.pdf\")\n",
        "cv_text = load_and_extract_text(\"CoverLetter/Data/CV_GPT_rev.pdf\")\n",
        "cover_letter_text = generate_cover_letter(model,cv_text, job_description).text\n",
        "for k in cover_letter_text.split(\".\"):\n",
        "  print(k)\n",
        "time.sleep(3)\n",
        "key_phrases = extract_key_phrases(model, cover_letter_text, job_description, num_phrases=3)\n",
        "for k in key_phrases:\n",
        "  print(\"#\"*30)\n",
        "  print(k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "CC26_KnJNl7k",
        "outputId": "6d82348b-857f-423c-9485-d8b7b6d0c97a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HERE\n",
            "Dear Hiring Manager,\n",
            "\n",
            "My experience as a Full Stack Machine Learning Engineer, particularly in the financial domain, aligns strongly with the requirements for the AI Developer position\n",
            " I have extensive experience developing and deploying predictive models, integrating data from diverse sources, and creating unified formats\n",
            " My work with portfolio management and investment analysis tools at Finzor Ltd\n",
            " demonstrates my ability to translate complex business requirements into technical solutions\n",
            " \n",
            "\n",
            "I am eager to leverage my expertise in AI and machine learning to contribute to your team's efforts in automating invoice reconciliation and standardizing financial data\n",
            " \n",
            "\n",
            "HERE\n",
            "##############################\n",
            "Here are the 3 most important words/phrases from the cover letter, aligned with the job description, and highlighting the candidate's skills:\n",
            "##############################\n",
            "\n",
            "##############################\n",
            "1. **Developing predictive models:**  This directly aligns with the job description's requirement to \"Develop and implement AI and machine learning models to automate invoice reconciliation.\"  It demonstrates the candidate's experience with a core task of the role.\n",
            "##############################\n",
            "2. **Integrating data from diverse sources:**  This matches the description's need for \"creating a unified data format across various financial systems.\"  It shows the candidate's ability to handle the complex data integration aspect of the job.\n",
            "##############################\n",
            "3. **Translating complex business requirements into technical solutions:**  This highlights the candidate's ability to bridge the gap between business needs and technical implementation. It aligns with the job description's emphasis on understanding business requirements and integrating AI solutions into existing workflows. \n",
            "##############################\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_strings(key_phrases):\n",
        "  R= []\n",
        "  for k in key_phrases:\n",
        "    A = (re.findall('\\*\\*.*?\\*\\*',k))\n",
        "    if len(A)>0:\n",
        "      R += re.findall('[A-Za-z\\ 0-9]+',A[0])\n",
        "  return R"
      ],
      "metadata": {
        "id": "ZPDpn1jp0eS1"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extract_strings(extract_key_phrases(model, cover_letter_text, job_description, num_phrases=3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "5IeUwuSB4tJx",
        "outputId": "9c30b64e-85df-44c5-f070-9a8da76dbf25"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HERE\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Developing and deploying predictive models',\n",
              " 'Integrating data from diverse sources',\n",
              " 'Translating complex business requirements into technical solutions']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from docx import Document\n",
        "from docx.shared import Pt\n",
        "from docx.oxml.ns import qn\n",
        "from docx.oxml import OxmlElement\n",
        "\n",
        "def bold_strings_in_text(text, bold_strings, output_doc):\n",
        "    # Create a new Document\n",
        "    doc = Document()\n",
        "\n",
        "    # Add the text to the document, with specified strings in bold\n",
        "    para = doc.add_paragraph()\n",
        "    parts = split_text(text, bold_strings)\n",
        "\n",
        "    for part in parts:\n",
        "        if part.lower() in [s.lower() for s in bold_strings]:\n",
        "            run = para.add_run(part)\n",
        "            run.bold = True\n",
        "        else:\n",
        "            para.add_run(part)\n",
        "\n",
        "    # Save the document\n",
        "    doc.save(output_doc)\n",
        "\n",
        "def split_text(text, bold_strings):\n",
        "    import re\n",
        "    pattern = '|'.join(re.escape(s) for s in bold_strings)\n",
        "    parts = re.split(f'({pattern})', text)\n",
        "    print(parts)\n",
        "    return parts\n",
        "\n",
        "# Example usage\n",
        "text = \"This is a sample text. We want some words like sample and words to be bold.\"\n",
        "bold_strings = [\"sample\", \"words\"]\n",
        "bold_strings_in_text(text, bold_strings,\"output.docx\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpV3EAEf5AQG",
        "outputId": "7ade4c07-13b0-4a20-9def-e6a4c1e7adfa"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['This is a ', 'sample', ' text. We want some ', 'words', ' like ', 'sample', ' and ', 'words', ' to be bold.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cl_text = generate_cover_letter(model,cv_text, job_description).text\n",
        "strings = extract_strings(extract_key_phrases(model, cl_text, job_description, num_phrases=3))\n",
        "bold_strings_in_text(cl_text, strings, \"test2.docx\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "Tqeq5Cgn5otS",
        "outputId": "34b108b0-5ee5-4204-9aa9-bd2063491151"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HERE\n",
            "HERE\n",
            "['Dear Hiring Manager,\\n\\nMy extensive experience in developing and deploying machine learning solutions, particularly in finance and data engineering, makes me an ideal candidate for the AI Developer position.  I possess a strong foundation in Python, ML frameworks (TensorFlow, PyTorch, scikit-learn), and ', 'NLP techniques', \", demonstrated through projects like Finzor and Palo Alto Networks. I'm eager to contribute my expertise to automating invoice reconciliation and creating a unified data format, leveraging my experience with data integration and model development. \\n\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(strings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCzpElqwdp_n",
        "outputId": "31361f4e-1959-4075-858f-fb0dca093233"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Developing AI models', 'NLP techniques', 'Data integration']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cl_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "37GpRjmhHvFW",
        "outputId": "5bbce3e0-a218-4439-c077-eee4616e0e58"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Dear Hiring Manager,\\n\\nMy extensive experience in developing and deploying machine learning solutions, particularly in finance and data engineering, makes me an ideal candidate for the AI Developer position.  I possess a strong foundation in Python, ML frameworks (TensorFlow, PyTorch, scikit-learn), and NLP techniques, demonstrated through projects like Finzor and Palo Alto Networks. I'm eager to contribute my expertise to automating invoice reconciliation and creating a unified data format, leveraging my experience with data integration and model development. \\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxWAcOH0dcDX",
        "outputId": "1caf4f80-b465-4100-e5b9-56e418ecad27"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CoverLetter  output.docx  sample_data  test2.docx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from docx import Document\n",
        "import re\n",
        "\n",
        "def bold_strings_in_text(text, bold_strings, output_doc):\n",
        "    # Create a new Document\n",
        "    doc = Document()\n",
        "\n",
        "    # Add the text to the document, with specified strings in bold\n",
        "    para = doc.add_paragraph()\n",
        "    parts = split_text(text, bold_strings)\n",
        "\n",
        "    for part in parts:\n",
        "        run = para.add_run(part)\n",
        "        if part.lower() in [s.lower() for s in bold_strings]:\n",
        "            run.bold = True\n",
        "\n",
        "    # Save the document\n",
        "    doc.save(output_doc)\n",
        "\n",
        "def split_text(text, bold_strings):\n",
        "    pattern = '|'.join(re.escape(s) for s in bold_strings)\n",
        "    parts = re.split(f'({pattern})', text, flags=re.IGNORECASE)\n",
        "    return parts\n",
        "\n",
        "# Example usage\n",
        "text = \"\"\"Dear Hiring Manager,\n",
        "\n",
        "I am writing to express my strong interest in the AI Developer position at your company. My extensive experience in developing and deploying AI solutions, particularly in finance and data analytics, aligns well with your requirements. My accomplishments include building predictive models from scratch, integrating data from diverse sources into unified formats, and creating adaptive models for updating anti-malware filters. I am confident that my skills and experience would be a valuable asset to your team.\n",
        "\"\"\"\n",
        "bold_strings = [\"Developing and deploying predictive models\", \"Integrating diverse data sources\", \"Creating intelligent systems for financial analysis\"]\n",
        "bold_strings_in_text(text, bold_strings, \"output.docx\")\n"
      ],
      "metadata": {
        "id": "hBZaP7xeJnCo"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from docx import Document\n",
        "import re\n",
        "\n",
        "def bold_strings_in_text(text, bold_strings, output_doc):\n",
        "    # Create a new Document\n",
        "    doc = Document()\n",
        "\n",
        "    # Add the text to the document, with specified strings in bold\n",
        "    para = doc.add_paragraph()\n",
        "    parts = split_text(text, bold_strings)\n",
        "\n",
        "    for part in parts:\n",
        "        run = para.add_run(part)\n",
        "        # Check if the part matches any bold string, ignoring case\n",
        "        if any(re.fullmatch(re.escape(b), part, re.IGNORECASE) for b in bold_strings):\n",
        "            run.bold = True\n",
        "\n",
        "    # Save the document\n",
        "    doc.save(output_doc)\n",
        "\n",
        "def split_text(text, bold_strings):\n",
        "    # Create a regex pattern to match any of the bold strings, case-insensitive\n",
        "    pattern = '|'.join(re.escape(s) for s in bold_strings)\n",
        "    parts = re.split(f'({pattern})', text, flags=re.IGNORECASE)\n",
        "    return parts\n",
        "\n",
        "# Example usage\n",
        "text = \"\"\"Dear Hiring Manager,\n",
        "\n",
        "I am writing to express my strong interest in the AI Developer position at your company. My extensive experience in developing and deploying AI solutions, particularly in finance and data analytics, aligns well with your requirements. My accomplishments include building predictive models from scratch, integrating data from diverse sources into unified formats, and creating adaptive models for updating anti-malware filters. I am confident that my skills and experience would be a valuable asset to your team.\n",
        "\"\"\"\n",
        "bold_strings = [\"developing and deploying AI solutions\", \"integrating data from diverse sources\", \"creating adaptive models\"]\n",
        "bold_strings_in_text(text, bold_strings, \"output_bold.docx\")\n"
      ],
      "metadata": {
        "id": "8WUPSI8YZCfj"
      },
      "execution_count": 27,
      "outputs": []
    }
  ]
}